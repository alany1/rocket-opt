{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70c70385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from matplotlib import pyplot as plt\n",
    "from tools import *\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.optimize import LinearConstraint, NonlinearConstraint, Bounds, minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2165a5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd7f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getObs(n):\n",
    "    obs = {}\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            df = pd.read_csv(f'rocket-results/{i}.csv')\n",
    "        except:\n",
    "            print('Missing', i)\n",
    "        obs[i] = df\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4c0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeConfig():\n",
    "    configs = {}\n",
    "    with open('sample_list.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    with open('sample_list_100.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    with open('sample_list_200.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    with open('sample_list_300.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30033ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = initializeConfig()\n",
    "obs = getObs(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7380f365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/y3gj2gld0zqfjtq_lhxz03t00000gn/T/ipykernel_30584/2135078581.py:5: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  data[i].append(obs[i].mean()['Stability Margin (cal)'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         3.734223\n",
       "1         7.875106\n",
       "2         2.509849\n",
       "3         7.372139\n",
       "4         8.753891\n",
       "5         7.977354\n",
       "6         7.539283\n",
       "7         8.558976\n",
       "8     32187.640000\n",
       "9         5.071216\n",
       "10       99.001530\n",
       "Name: 284, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "for i in range(len(config)):\n",
    "    data[i] = list(config[i]['S'].values()) + list(config[i]['B'].values())\n",
    "    data[i].append(obs[i].max()['Altitude (ft)'])\n",
    "    data[i].append(obs[i].mean()['Stability Margin (cal)'])\n",
    "    data[i].append(obs[i].max()['Time (sec)'])\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df.iloc[284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "467cb232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schord</th>\n",
       "      <th>Sspan</th>\n",
       "      <th>Ssweep</th>\n",
       "      <th>Stip</th>\n",
       "      <th>Bchord</th>\n",
       "      <th>Bspan</th>\n",
       "      <th>Bsweep</th>\n",
       "      <th>Btip</th>\n",
       "      <th>Schordspan</th>\n",
       "      <th>Schordsweep</th>\n",
       "      <th>...</th>\n",
       "      <th>SSweeptip</th>\n",
       "      <th>Bchordspan</th>\n",
       "      <th>Bchordsweep</th>\n",
       "      <th>Bchordtip</th>\n",
       "      <th>Bspansweep</th>\n",
       "      <th>BSpantip</th>\n",
       "      <th>BSweeptip</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.465233</td>\n",
       "      <td>9.191411</td>\n",
       "      <td>6.313146</td>\n",
       "      <td>6.181568</td>\n",
       "      <td>4.253219</td>\n",
       "      <td>3.362766</td>\n",
       "      <td>2.004250</td>\n",
       "      <td>3.767645</td>\n",
       "      <td>86.998844</td>\n",
       "      <td>59.755399</td>\n",
       "      <td>...</td>\n",
       "      <td>39.025144</td>\n",
       "      <td>14.302581</td>\n",
       "      <td>8.524515</td>\n",
       "      <td>16.024619</td>\n",
       "      <td>6.739826</td>\n",
       "      <td>12.669711</td>\n",
       "      <td>7.551304</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>-5.121752</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.050903</td>\n",
       "      <td>2.807665</td>\n",
       "      <td>7.250966</td>\n",
       "      <td>4.202998</td>\n",
       "      <td>7.871765</td>\n",
       "      <td>6.329711</td>\n",
       "      <td>3.563606</td>\n",
       "      <td>6.148326</td>\n",
       "      <td>14.181241</td>\n",
       "      <td>36.623926</td>\n",
       "      <td>...</td>\n",
       "      <td>30.475799</td>\n",
       "      <td>49.826002</td>\n",
       "      <td>28.051867</td>\n",
       "      <td>48.398181</td>\n",
       "      <td>22.556595</td>\n",
       "      <td>38.917130</td>\n",
       "      <td>21.910210</td>\n",
       "      <td>77117.160000</td>\n",
       "      <td>1.278655</td>\n",
       "      <td>154.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.796076</td>\n",
       "      <td>5.131824</td>\n",
       "      <td>8.469040</td>\n",
       "      <td>8.168441</td>\n",
       "      <td>6.226139</td>\n",
       "      <td>7.792487</td>\n",
       "      <td>6.816335</td>\n",
       "      <td>8.795342</td>\n",
       "      <td>45.139920</td>\n",
       "      <td>74.494323</td>\n",
       "      <td>...</td>\n",
       "      <td>69.178850</td>\n",
       "      <td>48.517110</td>\n",
       "      <td>42.439452</td>\n",
       "      <td>54.761021</td>\n",
       "      <td>53.116208</td>\n",
       "      <td>68.537590</td>\n",
       "      <td>59.951999</td>\n",
       "      <td>51216.000000</td>\n",
       "      <td>5.212006</td>\n",
       "      <td>125.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.590219</td>\n",
       "      <td>9.233072</td>\n",
       "      <td>6.352605</td>\n",
       "      <td>8.429602</td>\n",
       "      <td>5.672564</td>\n",
       "      <td>5.705322</td>\n",
       "      <td>5.717624</td>\n",
       "      <td>3.420081</td>\n",
       "      <td>51.614896</td>\n",
       "      <td>35.512459</td>\n",
       "      <td>...</td>\n",
       "      <td>53.549937</td>\n",
       "      <td>32.363803</td>\n",
       "      <td>32.433584</td>\n",
       "      <td>19.400628</td>\n",
       "      <td>32.620884</td>\n",
       "      <td>19.512664</td>\n",
       "      <td>19.554736</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>-2.489141</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.916229</td>\n",
       "      <td>4.216994</td>\n",
       "      <td>4.711545</td>\n",
       "      <td>6.462613</td>\n",
       "      <td>4.887217</td>\n",
       "      <td>2.638681</td>\n",
       "      <td>9.605809</td>\n",
       "      <td>5.234709</td>\n",
       "      <td>12.297724</td>\n",
       "      <td>13.739946</td>\n",
       "      <td>...</td>\n",
       "      <td>30.448892</td>\n",
       "      <td>12.895807</td>\n",
       "      <td>46.945675</td>\n",
       "      <td>25.583158</td>\n",
       "      <td>25.346667</td>\n",
       "      <td>13.812727</td>\n",
       "      <td>50.283615</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>-4.231226</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.608430</td>\n",
       "      <td>3.346465</td>\n",
       "      <td>5.201403</td>\n",
       "      <td>9.166944</td>\n",
       "      <td>6.192108</td>\n",
       "      <td>3.850187</td>\n",
       "      <td>7.960717</td>\n",
       "      <td>8.586406</td>\n",
       "      <td>8.729021</td>\n",
       "      <td>13.567499</td>\n",
       "      <td>...</td>\n",
       "      <td>47.680974</td>\n",
       "      <td>23.840776</td>\n",
       "      <td>49.293623</td>\n",
       "      <td>53.167952</td>\n",
       "      <td>30.650253</td>\n",
       "      <td>33.059270</td>\n",
       "      <td>68.353950</td>\n",
       "      <td>70830.750000</td>\n",
       "      <td>1.673402</td>\n",
       "      <td>149.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>7.801407</td>\n",
       "      <td>2.628427</td>\n",
       "      <td>5.543288</td>\n",
       "      <td>9.133362</td>\n",
       "      <td>7.014197</td>\n",
       "      <td>5.730589</td>\n",
       "      <td>4.246228</td>\n",
       "      <td>6.930445</td>\n",
       "      <td>20.505433</td>\n",
       "      <td>43.245446</td>\n",
       "      <td>...</td>\n",
       "      <td>50.628851</td>\n",
       "      <td>40.195478</td>\n",
       "      <td>29.783881</td>\n",
       "      <td>48.611503</td>\n",
       "      <td>24.333390</td>\n",
       "      <td>39.715531</td>\n",
       "      <td>29.428252</td>\n",
       "      <td>72485.310000</td>\n",
       "      <td>1.614970</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>7.364198</td>\n",
       "      <td>8.455093</td>\n",
       "      <td>4.617628</td>\n",
       "      <td>3.805883</td>\n",
       "      <td>4.280772</td>\n",
       "      <td>6.398586</td>\n",
       "      <td>8.552977</td>\n",
       "      <td>8.138172</td>\n",
       "      <td>62.264979</td>\n",
       "      <td>34.005123</td>\n",
       "      <td>...</td>\n",
       "      <td>17.574150</td>\n",
       "      <td>27.390888</td>\n",
       "      <td>36.613344</td>\n",
       "      <td>34.837657</td>\n",
       "      <td>54.726959</td>\n",
       "      <td>52.072793</td>\n",
       "      <td>69.605594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.734951</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>7.094305</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>2.934079</td>\n",
       "      <td>6.637124</td>\n",
       "      <td>4.526698</td>\n",
       "      <td>3.664447</td>\n",
       "      <td>4.901074</td>\n",
       "      <td>5.327160</td>\n",
       "      <td>17.190049</td>\n",
       "      <td>20.815255</td>\n",
       "      <td>...</td>\n",
       "      <td>19.473850</td>\n",
       "      <td>16.587847</td>\n",
       "      <td>22.185683</td>\n",
       "      <td>24.114444</td>\n",
       "      <td>17.959727</td>\n",
       "      <td>19.521095</td>\n",
       "      <td>26.108803</td>\n",
       "      <td>73446.170000</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3.451784</td>\n",
       "      <td>3.164933</td>\n",
       "      <td>3.213005</td>\n",
       "      <td>9.450705</td>\n",
       "      <td>8.759146</td>\n",
       "      <td>8.331735</td>\n",
       "      <td>2.206001</td>\n",
       "      <td>6.427374</td>\n",
       "      <td>10.924665</td>\n",
       "      <td>11.090597</td>\n",
       "      <td>...</td>\n",
       "      <td>30.365158</td>\n",
       "      <td>72.978885</td>\n",
       "      <td>19.322682</td>\n",
       "      <td>56.298306</td>\n",
       "      <td>18.379814</td>\n",
       "      <td>53.551178</td>\n",
       "      <td>14.178791</td>\n",
       "      <td>55933.920000</td>\n",
       "      <td>2.408665</td>\n",
       "      <td>131.0084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Schord     Sspan    Ssweep      Stip    Bchord     Bspan    Bsweep  \\\n",
       "0    9.465233  9.191411  6.313146  6.181568  4.253219  3.362766  2.004250   \n",
       "1    5.050903  2.807665  7.250966  4.202998  7.871765  6.329711  3.563606   \n",
       "2    8.796076  5.131824  8.469040  8.168441  6.226139  7.792487  6.816335   \n",
       "3    5.590219  9.233072  6.352605  8.429602  5.672564  5.705322  5.717624   \n",
       "4    2.916229  4.216994  4.711545  6.462613  4.887217  2.638681  9.605809   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  2.608430  3.346465  5.201403  9.166944  6.192108  3.850187  7.960717   \n",
       "396  7.801407  2.628427  5.543288  9.133362  7.014197  5.730589  4.246228   \n",
       "397  7.364198  8.455093  4.617628  3.805883  4.280772  6.398586  8.552977   \n",
       "398  7.094305  2.423077  2.934079  6.637124  4.526698  3.664447  4.901074   \n",
       "399  3.451784  3.164933  3.213005  9.450705  8.759146  8.331735  2.206001   \n",
       "\n",
       "         Btip  Schordspan  Schordsweep  ...  SSweeptip  Bchordspan  \\\n",
       "0    3.767645   86.998844    59.755399  ...  39.025144   14.302581   \n",
       "1    6.148326   14.181241    36.623926  ...  30.475799   49.826002   \n",
       "2    8.795342   45.139920    74.494323  ...  69.178850   48.517110   \n",
       "3    3.420081   51.614896    35.512459  ...  53.549937   32.363803   \n",
       "4    5.234709   12.297724    13.739946  ...  30.448892   12.895807   \n",
       "..        ...         ...          ...  ...        ...         ...   \n",
       "395  8.586406    8.729021    13.567499  ...  47.680974   23.840776   \n",
       "396  6.930445   20.505433    43.245446  ...  50.628851   40.195478   \n",
       "397  8.138172   62.264979    34.005123  ...  17.574150   27.390888   \n",
       "398  5.327160   17.190049    20.815255  ...  19.473850   16.587847   \n",
       "399  6.427374   10.924665    11.090597  ...  30.365158   72.978885   \n",
       "\n",
       "     Bchordsweep  Bchordtip  Bspansweep   BSpantip  BSweeptip      Altitude  \\\n",
       "0       8.524515  16.024619    6.739826  12.669711   7.551304      0.004903   \n",
       "1      28.051867  48.398181   22.556595  38.917130  21.910210  77117.160000   \n",
       "2      42.439452  54.761021   53.116208  68.537590  59.951999  51216.000000   \n",
       "3      32.433584  19.400628   32.620884  19.512664  19.554736      0.004691   \n",
       "4      46.945675  25.583158   25.346667  13.812727  50.283615      0.004818   \n",
       "..           ...        ...         ...        ...        ...           ...   \n",
       "395    49.293623  53.167952   30.650253  33.059270  68.353950  70830.750000   \n",
       "396    29.783881  48.611503   24.333390  39.715531  29.428252  72485.310000   \n",
       "397    36.613344  34.837657   54.726959  52.072793  69.605594      0.000000   \n",
       "398    22.185683  24.114444   17.959727  19.521095  26.108803  73446.170000   \n",
       "399    19.322682  56.298306   18.379814  53.551178  14.178791  55933.920000   \n",
       "\n",
       "     Stability      Time  \n",
       "0    -5.121752    0.0100  \n",
       "1     1.278655  154.9973  \n",
       "2     5.212006  125.0071  \n",
       "3    -2.489141    0.0100  \n",
       "4    -4.231226    0.0100  \n",
       "..         ...       ...  \n",
       "395   1.673402  149.0006  \n",
       "396   1.614970  150.9995  \n",
       "397  -1.734951    0.0000  \n",
       "398   0.853824  150.9995  \n",
       "399   2.408665  131.0084  \n",
       "\n",
       "[400 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={0: \"Schord\", 1: \"Sspan\", 2: \"Ssweep\", 3: \"Stip\", 4: \"Bchord\", \n",
    "                        5: \"Bspan\", 6: \"Bsweep\", 7: \"Btip\", 8: \"Altitude\", 9: \"Stability\", 10: \"Time\"})\n",
    "df['Schordspan'] = df['Schord'] * df['Sspan']\n",
    "df['Schordsweep'] = df['Schord'] * df['Ssweep']\n",
    "df['Schordtip'] = df['Schord'] * df['Stip']\n",
    "df['Sspansweep'] = df['Sspan'] * df['Ssweep']\n",
    "df['SSpantip'] = df['Sspan'] * df['Stip']\n",
    "df['SSweeptip'] = df['Ssweep'] * df['Stip']\n",
    "\n",
    "df['Bchordspan'] = df['Bchord'] * df['Bspan']\n",
    "df['Bchordsweep'] = df['Bchord'] * df['Bsweep']\n",
    "df['Bchordtip'] = df['Bchord'] * df['Btip']\n",
    "df['Bspansweep'] = df['Bspan'] * df['Bsweep']\n",
    "df['BSpantip'] = df['Bspan'] * df['Btip']\n",
    "df['BSweeptip'] = df['Bsweep'] * df['Btip']\n",
    "alt = df.pop(\"Altitude\")\n",
    "stab = df.pop(\"Stability\")\n",
    "time = df.pop(\"Time\")\n",
    "\n",
    "df.insert(len(df.columns), \"Altitude\", alt)\n",
    "df.insert(len(df.columns), \"Stability\", stab)\n",
    "df.insert(len(df.columns), \"Time\", time)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2bd6b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schord</th>\n",
       "      <th>Sspan</th>\n",
       "      <th>Ssweep</th>\n",
       "      <th>Stip</th>\n",
       "      <th>Bchord</th>\n",
       "      <th>Bspan</th>\n",
       "      <th>Bsweep</th>\n",
       "      <th>Btip</th>\n",
       "      <th>Schordspan</th>\n",
       "      <th>Schordsweep</th>\n",
       "      <th>...</th>\n",
       "      <th>SSweeptip</th>\n",
       "      <th>Bchordspan</th>\n",
       "      <th>Bchordsweep</th>\n",
       "      <th>Bchordtip</th>\n",
       "      <th>Bspansweep</th>\n",
       "      <th>BSpantip</th>\n",
       "      <th>BSweeptip</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.050903</td>\n",
       "      <td>2.807665</td>\n",
       "      <td>7.250966</td>\n",
       "      <td>4.202998</td>\n",
       "      <td>7.871765</td>\n",
       "      <td>6.329711</td>\n",
       "      <td>3.563606</td>\n",
       "      <td>6.148326</td>\n",
       "      <td>14.181241</td>\n",
       "      <td>36.623926</td>\n",
       "      <td>...</td>\n",
       "      <td>30.475799</td>\n",
       "      <td>49.826002</td>\n",
       "      <td>28.051867</td>\n",
       "      <td>48.398181</td>\n",
       "      <td>22.556595</td>\n",
       "      <td>38.917130</td>\n",
       "      <td>21.910210</td>\n",
       "      <td>77117.16</td>\n",
       "      <td>1.278655</td>\n",
       "      <td>154.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.796076</td>\n",
       "      <td>5.131824</td>\n",
       "      <td>8.469040</td>\n",
       "      <td>8.168441</td>\n",
       "      <td>6.226139</td>\n",
       "      <td>7.792487</td>\n",
       "      <td>6.816335</td>\n",
       "      <td>8.795342</td>\n",
       "      <td>45.139920</td>\n",
       "      <td>74.494323</td>\n",
       "      <td>...</td>\n",
       "      <td>69.178850</td>\n",
       "      <td>48.517110</td>\n",
       "      <td>42.439452</td>\n",
       "      <td>54.761021</td>\n",
       "      <td>53.116208</td>\n",
       "      <td>68.537590</td>\n",
       "      <td>59.951999</td>\n",
       "      <td>51216.00</td>\n",
       "      <td>5.212006</td>\n",
       "      <td>125.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.562160</td>\n",
       "      <td>4.337768</td>\n",
       "      <td>7.930397</td>\n",
       "      <td>4.372560</td>\n",
       "      <td>9.417980</td>\n",
       "      <td>8.246008</td>\n",
       "      <td>2.728282</td>\n",
       "      <td>6.326085</td>\n",
       "      <td>37.140668</td>\n",
       "      <td>67.901332</td>\n",
       "      <td>...</td>\n",
       "      <td>34.676133</td>\n",
       "      <td>77.660732</td>\n",
       "      <td>25.694900</td>\n",
       "      <td>59.578937</td>\n",
       "      <td>22.497430</td>\n",
       "      <td>52.164942</td>\n",
       "      <td>17.259340</td>\n",
       "      <td>54082.50</td>\n",
       "      <td>4.485508</td>\n",
       "      <td>129.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.703811</td>\n",
       "      <td>2.188438</td>\n",
       "      <td>9.143090</td>\n",
       "      <td>2.635864</td>\n",
       "      <td>9.087634</td>\n",
       "      <td>8.094306</td>\n",
       "      <td>6.826608</td>\n",
       "      <td>3.754130</td>\n",
       "      <td>19.047753</td>\n",
       "      <td>79.579730</td>\n",
       "      <td>...</td>\n",
       "      <td>24.099946</td>\n",
       "      <td>73.558093</td>\n",
       "      <td>62.037714</td>\n",
       "      <td>34.116158</td>\n",
       "      <td>55.256655</td>\n",
       "      <td>30.387077</td>\n",
       "      <td>25.627973</td>\n",
       "      <td>78784.51</td>\n",
       "      <td>0.613785</td>\n",
       "      <td>156.9962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.074672</td>\n",
       "      <td>3.479253</td>\n",
       "      <td>5.061755</td>\n",
       "      <td>2.201202</td>\n",
       "      <td>8.430403</td>\n",
       "      <td>6.003352</td>\n",
       "      <td>2.080965</td>\n",
       "      <td>3.394916</td>\n",
       "      <td>28.093824</td>\n",
       "      <td>40.872014</td>\n",
       "      <td>...</td>\n",
       "      <td>11.141944</td>\n",
       "      <td>50.610675</td>\n",
       "      <td>17.543371</td>\n",
       "      <td>28.620512</td>\n",
       "      <td>12.492762</td>\n",
       "      <td>20.380874</td>\n",
       "      <td>7.064700</td>\n",
       "      <td>59576.45</td>\n",
       "      <td>2.920013</td>\n",
       "      <td>136.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>5.247843</td>\n",
       "      <td>7.799644</td>\n",
       "      <td>8.441005</td>\n",
       "      <td>9.658211</td>\n",
       "      <td>6.937770</td>\n",
       "      <td>7.882306</td>\n",
       "      <td>6.353957</td>\n",
       "      <td>9.196173</td>\n",
       "      <td>40.931306</td>\n",
       "      <td>44.297067</td>\n",
       "      <td>...</td>\n",
       "      <td>81.524999</td>\n",
       "      <td>54.685626</td>\n",
       "      <td>44.082290</td>\n",
       "      <td>63.800932</td>\n",
       "      <td>50.083829</td>\n",
       "      <td>72.487046</td>\n",
       "      <td>58.432082</td>\n",
       "      <td>39893.78</td>\n",
       "      <td>5.851534</td>\n",
       "      <td>111.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.608430</td>\n",
       "      <td>3.346465</td>\n",
       "      <td>5.201403</td>\n",
       "      <td>9.166944</td>\n",
       "      <td>6.192108</td>\n",
       "      <td>3.850187</td>\n",
       "      <td>7.960717</td>\n",
       "      <td>8.586406</td>\n",
       "      <td>8.729021</td>\n",
       "      <td>13.567499</td>\n",
       "      <td>...</td>\n",
       "      <td>47.680974</td>\n",
       "      <td>23.840776</td>\n",
       "      <td>49.293623</td>\n",
       "      <td>53.167952</td>\n",
       "      <td>30.650253</td>\n",
       "      <td>33.059270</td>\n",
       "      <td>68.353950</td>\n",
       "      <td>70830.75</td>\n",
       "      <td>1.673402</td>\n",
       "      <td>149.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>7.801407</td>\n",
       "      <td>2.628427</td>\n",
       "      <td>5.543288</td>\n",
       "      <td>9.133362</td>\n",
       "      <td>7.014197</td>\n",
       "      <td>5.730589</td>\n",
       "      <td>4.246228</td>\n",
       "      <td>6.930445</td>\n",
       "      <td>20.505433</td>\n",
       "      <td>43.245446</td>\n",
       "      <td>...</td>\n",
       "      <td>50.628851</td>\n",
       "      <td>40.195478</td>\n",
       "      <td>29.783881</td>\n",
       "      <td>48.611503</td>\n",
       "      <td>24.333390</td>\n",
       "      <td>39.715531</td>\n",
       "      <td>29.428252</td>\n",
       "      <td>72485.31</td>\n",
       "      <td>1.614970</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>7.094305</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>2.934079</td>\n",
       "      <td>6.637124</td>\n",
       "      <td>4.526698</td>\n",
       "      <td>3.664447</td>\n",
       "      <td>4.901074</td>\n",
       "      <td>5.327160</td>\n",
       "      <td>17.190049</td>\n",
       "      <td>20.815255</td>\n",
       "      <td>...</td>\n",
       "      <td>19.473850</td>\n",
       "      <td>16.587847</td>\n",
       "      <td>22.185683</td>\n",
       "      <td>24.114444</td>\n",
       "      <td>17.959727</td>\n",
       "      <td>19.521095</td>\n",
       "      <td>26.108803</td>\n",
       "      <td>73446.17</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3.451784</td>\n",
       "      <td>3.164933</td>\n",
       "      <td>3.213005</td>\n",
       "      <td>9.450705</td>\n",
       "      <td>8.759146</td>\n",
       "      <td>8.331735</td>\n",
       "      <td>2.206001</td>\n",
       "      <td>6.427374</td>\n",
       "      <td>10.924665</td>\n",
       "      <td>11.090597</td>\n",
       "      <td>...</td>\n",
       "      <td>30.365158</td>\n",
       "      <td>72.978885</td>\n",
       "      <td>19.322682</td>\n",
       "      <td>56.298306</td>\n",
       "      <td>18.379814</td>\n",
       "      <td>53.551178</td>\n",
       "      <td>14.178791</td>\n",
       "      <td>55933.92</td>\n",
       "      <td>2.408665</td>\n",
       "      <td>131.0084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Schord     Sspan    Ssweep      Stip    Bchord     Bspan    Bsweep  \\\n",
       "1    5.050903  2.807665  7.250966  4.202998  7.871765  6.329711  3.563606   \n",
       "2    8.796076  5.131824  8.469040  8.168441  6.226139  7.792487  6.816335   \n",
       "5    8.562160  4.337768  7.930397  4.372560  9.417980  8.246008  2.728282   \n",
       "6    8.703811  2.188438  9.143090  2.635864  9.087634  8.094306  6.826608   \n",
       "8    8.074672  3.479253  5.061755  2.201202  8.430403  6.003352  2.080965   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "393  5.247843  7.799644  8.441005  9.658211  6.937770  7.882306  6.353957   \n",
       "395  2.608430  3.346465  5.201403  9.166944  6.192108  3.850187  7.960717   \n",
       "396  7.801407  2.628427  5.543288  9.133362  7.014197  5.730589  4.246228   \n",
       "398  7.094305  2.423077  2.934079  6.637124  4.526698  3.664447  4.901074   \n",
       "399  3.451784  3.164933  3.213005  9.450705  8.759146  8.331735  2.206001   \n",
       "\n",
       "         Btip  Schordspan  Schordsweep  ...  SSweeptip  Bchordspan  \\\n",
       "1    6.148326   14.181241    36.623926  ...  30.475799   49.826002   \n",
       "2    8.795342   45.139920    74.494323  ...  69.178850   48.517110   \n",
       "5    6.326085   37.140668    67.901332  ...  34.676133   77.660732   \n",
       "6    3.754130   19.047753    79.579730  ...  24.099946   73.558093   \n",
       "8    3.394916   28.093824    40.872014  ...  11.141944   50.610675   \n",
       "..        ...         ...          ...  ...        ...         ...   \n",
       "393  9.196173   40.931306    44.297067  ...  81.524999   54.685626   \n",
       "395  8.586406    8.729021    13.567499  ...  47.680974   23.840776   \n",
       "396  6.930445   20.505433    43.245446  ...  50.628851   40.195478   \n",
       "398  5.327160   17.190049    20.815255  ...  19.473850   16.587847   \n",
       "399  6.427374   10.924665    11.090597  ...  30.365158   72.978885   \n",
       "\n",
       "     Bchordsweep  Bchordtip  Bspansweep   BSpantip  BSweeptip  Altitude  \\\n",
       "1      28.051867  48.398181   22.556595  38.917130  21.910210  77117.16   \n",
       "2      42.439452  54.761021   53.116208  68.537590  59.951999  51216.00   \n",
       "5      25.694900  59.578937   22.497430  52.164942  17.259340  54082.50   \n",
       "6      62.037714  34.116158   55.256655  30.387077  25.627973  78784.51   \n",
       "8      17.543371  28.620512   12.492762  20.380874   7.064700  59576.45   \n",
       "..           ...        ...         ...        ...        ...       ...   \n",
       "393    44.082290  63.800932   50.083829  72.487046  58.432082  39893.78   \n",
       "395    49.293623  53.167952   30.650253  33.059270  68.353950  70830.75   \n",
       "396    29.783881  48.611503   24.333390  39.715531  29.428252  72485.31   \n",
       "398    22.185683  24.114444   17.959727  19.521095  26.108803  73446.17   \n",
       "399    19.322682  56.298306   18.379814  53.551178  14.178791  55933.92   \n",
       "\n",
       "     Stability      Time  \n",
       "1     1.278655  154.9973  \n",
       "2     5.212006  125.0071  \n",
       "5     4.485508  129.0079  \n",
       "6     0.613785  156.9962  \n",
       "8     2.920013  136.0078  \n",
       "..         ...       ...  \n",
       "393   5.851534  111.0041  \n",
       "395   1.673402  149.0006  \n",
       "396   1.614970  150.9995  \n",
       "398   0.853824  150.9995  \n",
       "399   2.408665  131.0084  \n",
       "\n",
       "[197 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df['Time'] > 90]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed31cd",
   "metadata": {},
   "source": [
    "# NN Stability Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c4c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(45, 90)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(90, 60)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(60, 30)\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "        self.linear4 = torch.nn.Linear(30, 10)\n",
    "        self.activation4 = torch.nn.ReLU()\n",
    "        self.linear5 = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.activation4(x)\n",
    "        x = self.linear5(x)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58982d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arrays(data_arrays, batch_size, train = True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5610647",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = Classifier()\n",
    "classif.double()\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "raw_X = df.iloc[:,:8]\n",
    "raw_Y = df.iloc[:,-1] > 90\n",
    "batch_size = 10\n",
    "idxs = np.array(range(400)) #np.array(list(range(300, 400)) + list(range(200))) # FOR CV\n",
    "\n",
    "train_X = torch.from_numpy(poly.fit_transform(raw_X.iloc[idxs])).double()\n",
    "train_Y = torch.from_numpy(np.array([[x] for x in raw_Y.iloc[idxs]])).double()\n",
    "\n",
    "#test_X = torch.from_numpy(poly.fit_transform(raw_X[200:300])).double()\n",
    "#test_Y = torch.from_numpy(np.array([[x] for x in raw_Y[200:300]])).double()\n",
    "data_iter = load_arrays((train_X, train_Y), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99b49db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "trainer = torch.optim.SGD(classif.parameters(), lr=0.01)\n",
    "num_epochs = 250\n",
    "def train(num_epochs, trainer, loss):\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for X, y in data_iter:\n",
    "            X.requires_grad = True\n",
    "            l = loss(classif(X) ,y)\n",
    "\n",
    "            trainer.zero_grad() #sets gradients to zero\n",
    "\n",
    "            l.backward() # back propagation\n",
    "\n",
    "            trainer.step() # parameter update\n",
    "\n",
    "        l = loss(classif(train_X), train_Y)\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "            #print(X.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5677d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.363662\n",
      "epoch 51, loss 0.039084\n",
      "epoch 101, loss 0.018869\n",
      "epoch 151, loss 0.001382\n",
      "epoch 201, loss 0.000471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, tensor([1.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(num_epochs, trainer, loss), sum((classif(train_X) >= 0.5) == train_Y)/len(train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef056344",
   "metadata": {},
   "source": [
    "# Altitude Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be02a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.9933903267684263\n",
      "Train RMSE 1222.160451122849\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "raw = filtered_df.iloc[:,:8]\n",
    "#qr = LinearRegression()\n",
    "idxs = np.array(list(range(197)))# + list(range(50)))\n",
    "\n",
    "ridge = Ridge(alpha=0.6)\n",
    "ridge.fit(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3])\n",
    "#lasso = Lasso(alpha=.2)\n",
    "#lasso.fit(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3])\n",
    "\n",
    "#qr.fit(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3])\n",
    "print('R2', ridge.score(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3]))\n",
    "#print('Test RMSE Quad', np.sqrt(MSE(filtered_df.iloc[150:, -3], qr.predict(poly.fit_transform(raw[150:])))))\n",
    "#print('Test RMSE ridge', np.sqrt(MSE(filtered_df.iloc[150:, -3], ridge.predict(poly.fit_transform(raw[150:])))))\n",
    "#print('Test RMSE lasso', np.sqrt(MSE(filtered_df.iloc[150:, -3], lasso.predict(poly.fit_transform(raw[150:])))))\n",
    "\n",
    "print('Train RMSE', np.sqrt(MSE(filtered_df.iloc[idxs, -3], ridge.predict(poly.fit_transform(raw.iloc[idxs])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7976c7f9",
   "metadata": {},
   "source": [
    "# Solving COP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "909ca06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (linear1): Linear(in_features=45, out_features=90, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=90, out_features=60, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=60, out_features=30, bias=True)\n",
       "  (activation3): ReLU()\n",
       "  (linear4): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (activation4): ReLU()\n",
       "  (linear5): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stab_constraint(X):\n",
    "    with torch.no_grad():\n",
    "        return classif(torch.from_numpy(poly.fit_transform([X])))[0] - 0.6\n",
    "def l0(X):\n",
    "    return X[0]-2\n",
    "def l1(X):\n",
    "    return X[1]-2\n",
    "def l2(X):\n",
    "    return X[2]-2\n",
    "def l3(X):\n",
    "    return X[3]-2\n",
    "def l4(X):\n",
    "    return X[4]-2\n",
    "def l5(X):\n",
    "    return X[5]-2\n",
    "def l6(X):\n",
    "    return X[6]-2\n",
    "def l7(X):\n",
    "    return X[7]-2\n",
    "\n",
    "def u0(X):\n",
    "    return 10-X[0]\n",
    "def u1(X):\n",
    "    return 10-X[1]\n",
    "def u2(X):\n",
    "    return 10-X[2]\n",
    "def u3(X):\n",
    "    return 10-X[3]\n",
    "def u4(X):\n",
    "    return 10-X[4]\n",
    "def u5(X):\n",
    "    return 10-X[5]\n",
    "def u6(X):\n",
    "    return 10-X[6]\n",
    "def u7(X):\n",
    "    return 10-X[7]\n",
    "def objective(X):\n",
    "    return -ridge.predict(poly.fit_transform([X]))[0]\n",
    "classif.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d86bec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ineq_cons = {'type': 'ineq',\n",
    "             'fun' : stab_constraint}\n",
    "L0 = {'type': 'ineq',\n",
    "             'fun' : l0}\n",
    "L1 = {'type': 'ineq',\n",
    "             'fun' : l1}\n",
    "L2 = {'type': 'ineq',\n",
    "             'fun' : l2}\n",
    "L3 = {'type': 'ineq',\n",
    "             'fun' : l3}\n",
    "L4 = {'type': 'ineq',\n",
    "             'fun' : l4}\n",
    "L5 = {'type': 'ineq',\n",
    "             'fun' : l5}\n",
    "L6 = {'type': 'ineq',\n",
    "             'fun' : l6}\n",
    "L7 = {'type': 'ineq',\n",
    "             'fun' : l7}\n",
    "U0 = {'type': 'ineq',\n",
    "             'fun' : u0}\n",
    "U1 = {'type': 'ineq',\n",
    "             'fun' : u1}\n",
    "U2 = {'type': 'ineq',\n",
    "             'fun' : u2}\n",
    "U3 = {'type': 'ineq',\n",
    "             'fun' : u3}\n",
    "U4 = {'type': 'ineq',\n",
    "             'fun' : u4}\n",
    "U5 = {'type': 'ineq',\n",
    "             'fun' : u5}\n",
    "U6 = {'type': 'ineq',\n",
    "             'fun' : u6}\n",
    "U7 = {'type': 'ineq',\n",
    "             'fun' : u7}\n",
    "# x = minimize(objective, X0, method='trust-constr', options = {'disp':True}).x#, constraints = [ineq_cons], options={'ftol': 1e-9, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c5f1ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "samples = filtered_df.iloc[np.random.choice(len(filtered_df), 197), :8]\n",
    "results = []\n",
    "for i in range(len(samples)):\n",
    "    X0 = np.array(samples.iloc[i])\n",
    "    res = minimize(objective, X0, method='COBYLA', \n",
    "               constraints = [ineq_cons, L0, L1, L2, L3, L4, L5, L6, L7, U0, U1, U2, U3, U4, U5, U6, U7], \n",
    "               options = {'verbose':1, 'display':1, 'maxiter':10}) # constraints = [constraint], options = {'verbose':1})#, bounds = bounds)\n",
    "    results.append((X0, res.x, -res.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1c480ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([ 8.37781964,  2.        , 10.        ,  3.78840952,  4.72647194,\n",
       "          3.82683827,  9.23497365,  8.51699631]),\n",
       "  99990.03446809443),\n",
       " (array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([ 8.37781964,  2.        , 10.        ,  3.78840952,  4.72647194,\n",
       "          3.82683827,  9.23497365,  8.51699631]),\n",
       "  99990.03446809443),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([2.87590522, 2.        , 7.79436646, 7.1287923 , 5.34349866,\n",
       "         3.48989421, 5.66564727, 3.70702818]),\n",
       "  99108.85424540826),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([2.87590522, 2.        , 7.79436646, 7.1287923 , 5.34349866,\n",
       "         3.48989421, 5.66564727, 3.70702818]),\n",
       "  99108.85424540826),\n",
       " (array([2.32452262, 2.58871554, 9.32749721, 9.99315489, 4.52452962,\n",
       "         7.02169385, 4.2840132 , 2.97129558]),\n",
       "  array([ 2.04301842,  2.        , 10.        ,  9.85306499,  4.3865873 ,\n",
       "          6.39945625,  5.48669919,  2.97060992]),\n",
       "  97665.0784455041),\n",
       " (array([5.21541801, 3.2452491 , 8.89373312, 5.15294394, 7.57586859,\n",
       "         4.11137217, 7.01092286, 2.74712375]),\n",
       "  array([ 5.12875602,  2.27630273, 10.        ,  5.13481971,  7.51955764,\n",
       "          3.91592027,  8.03480318,  3.75542176]),\n",
       "  97529.87612909876),\n",
       " (array([5.21541801, 3.2452491 , 8.89373312, 5.15294394, 7.57586859,\n",
       "         4.11137217, 7.01092286, 2.74712375]),\n",
       "  array([ 5.12875602,  2.27630273, 10.        ,  5.13481971,  7.51955764,\n",
       "          3.91592027,  8.03480318,  3.75542176]),\n",
       "  97529.87612909876),\n",
       " (array([5.21541801, 3.2452491 , 8.89373312, 5.15294394, 7.57586859,\n",
       "         4.11137217, 7.01092286, 2.74712375]),\n",
       "  array([ 5.12875602,  2.27630273, 10.        ,  5.13481971,  7.51955764,\n",
       "          3.91592027,  8.03480318,  3.75542176]),\n",
       "  97529.87612909876),\n",
       " (array([2.18813213, 2.9292535 , 9.03466641, 7.78791587, 3.77742236,\n",
       "         6.61714789, 2.36987329, 4.4287817 ]),\n",
       "  array([ 2.05427848,  2.        , 10.        ,  7.73519326,  3.72286974,\n",
       "          6.30075043,  3.47672048,  4.41929283]),\n",
       "  97505.21690388097),\n",
       " (array([4.33129396, 3.20238894, 9.66627147, 3.24857185, 8.74241455,\n",
       "         5.19331968, 9.87308596, 9.479611  ]),\n",
       "  array([4.24805152, 2.23641309, 9.8471118 , 3.23839523, 8.71013078,\n",
       "         5.03202919, 9.88293463, 9.48044913]),\n",
       "  96680.2825257944)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key = lambda x: x[2], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb338637",
   "metadata": {},
   "source": [
    "# Alternative Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0697d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinateAscentQuad(stab_classifier, alt_predictor, initial = [0,0,0,0,0,0,0,0], inc = 0.0000001, max_iter = 10000, confidence = 0.95):\n",
    "    '''\n",
    "    Keep increasing in direction until unstable. \n",
    "    '''\n",
    "    M = {}\n",
    "    c = 9\n",
    "    for i in range(8):\n",
    "        for j in range(i, 8):\n",
    "            M[(i,j)] = c\n",
    "            c += 1\n",
    "    def partials(x):\n",
    "        grad = []\n",
    "        coef = alt_predictor.coef_\n",
    "        for i in range(8):\n",
    "            g = coef[1 + i]\n",
    "            for j in range(8):\n",
    "                if i == j:\n",
    "                    g += 2*x[i]*coef[M[i,i]]\n",
    "                else:\n",
    "                    g += coef[M[min([i,j]), max([i,j])]]*x[j]\n",
    "            grad.append(g)\n",
    "        return np.array(grad)\n",
    "    \n",
    "    x = initial\n",
    "    old = qr.predict(poly.fit_transform([x]))\n",
    "    for _ in range(max_iter):\n",
    "        #for i in range(8):\n",
    "        y = np.array(x)\n",
    "        # y[i] += np.sign(alt_predictor.coef_[i])*inc\n",
    "        # print(y, partials(x)*inc)\n",
    "        y += partials(x) * inc\n",
    "        if np.all(y > 2.5) and qr.predict(poly.fit_transform([y])) > old:\n",
    "            nxt = stab_classifier(torch.from_numpy(poly.fit_transform([y])))[0]\n",
    "            if nxt > confidence or np.random.rand() > 0.5:\n",
    "                if nxt <= confidence:\n",
    "                    print('Non greedy step')\n",
    "                x = y[:]\n",
    "                #print(qr.predict(poly.fit_transform([y])) - old)\n",
    "                old = qr.predict(poly.fit_transform([y]))\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print('No more feasible directions at iteration', _, '.', qr.predict(poly.fit_transform([x])) - qr.predict(poly.fit_transform([initial])))\n",
    "        break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "90d4800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.83000503 3.1276826  3.02323138 9.23555348 2.24817777 7.03314596\n",
      " 8.09570781 9.44711057] [57975.68378887] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[57975.68378887] [8.83000503 3.1276826  3.02323138 9.23555348 2.24817777 7.03314596\n",
      " 8.09570781 9.44711057] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 187 . [3788.5]\n",
      "[3.02924659 2.74524202 6.29978985 7.17708261 5.44099747 3.88833632\n",
      " 4.58883198 2.70679481] [82320.70196611] tensor([[0.9989]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[85849.063644] [3.0115428  2.50048433 6.35845087 7.17251176 5.43026482 3.84269922\n",
      " 4.59815405 2.70692833] tensor([[0.9986]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4483 . [36519.]\n",
      "[3.3540051  6.14184468 4.14507689 7.70715658 5.39638998 8.50625557\n",
      " 5.5111194  9.66804906] [38703.82607316] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73851.70633789] [3.11796602 2.5010328  5.28486909 7.59647652 5.37510492 8.08978272\n",
      " 5.68624821 9.56462436] tensor([[0.8342]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.08199065 8.40358411 5.89640539 4.42759739 7.53155837 9.71729336\n",
      " 3.73004212 6.38113378] [36257.16387281] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36257.16387281] [6.08199065 8.40358411 5.89640539 4.42759739 7.53155837 9.71729336\n",
      " 3.73004212 6.38113378] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[3.13647961 8.48256887 3.92780283 8.36598977 3.9629386  9.09679814\n",
      " 8.10348771 4.7824802 ] [33025.59400564] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[33025.95353924] [3.13649289 8.48250358 3.92796837 8.36596527 3.9629314  9.09684036\n",
      " 8.10346432 4.78244658] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.39264145 2.27191115 2.46288536 3.14119009 3.8611725  6.42414569\n",
      " 6.1764177  6.65003673] [70165.37270756] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70165.37270756] [4.39264145 2.27191115 2.46288536 3.14119009 3.8611725  6.42414569\n",
      " 6.1764177  6.65003673] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 318 . [5185.75]\n",
      "[6.06170208 2.87496314 6.90281982 2.70510471 7.12808567 6.70217093\n",
      " 3.84531715 3.59228077] [72725.73585299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77536.43766143] [6.02908693 2.50034578 6.9854691  2.70532951 7.11357809 6.63909737\n",
      " 3.86743006 3.59457598] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.0492438  3.76322981 5.37982854 5.86245733 4.71079861 5.4551199\n",
      " 6.22584348 9.5382352 ] [65400.96272759] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[65400.96272759] [2.0492438  3.76322981 5.37982854 5.86245733 4.71079861 5.4551199\n",
      " 6.22584348 9.5382352 ] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.51240616 6.89222388 2.27433044 4.54304472 7.5555095  9.23104571\n",
      " 6.35526986 2.10700777] [32790.12947708] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32790.12947708] [7.51240616 6.89222388 2.27433044 4.54304472 7.5555095  9.23104571\n",
      " 6.35526986 2.10700777] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 108 . [1759.5]\n",
      "[7.80140724 2.62842748 5.54328779 9.13336153 7.01419669 5.73058897\n",
      " 4.2462284  6.93044481] [71446.04961701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73105.28787059] [7.79091898 2.50056969 5.57366675 9.12978068 7.01033335 5.70911804\n",
      " 4.25315685 6.93010543] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] [55912.15024953] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[55912.15024953] [5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.51324278 3.07721551 6.85920372 6.88783709 9.21928215 6.05656858\n",
      " 5.77688879 2.11950605] [73219.8737354] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73219.8737354] [3.51324278 3.07721551 6.85920372 6.88783709 9.21928215 6.05656858\n",
      " 5.77688879 2.11950605] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] [56321.8718417] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56321.8718417] [3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[5.0058681  6.10893665 4.29003155 4.94664391 8.75459312 8.26696262\n",
      " 8.48254088 5.12644021] [39828.71859378] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[69375.69414889] [4.78560505 2.87549859 5.29838677 4.918143   8.62416923 8.00241956\n",
      " 8.5397044  5.12533597] tensor([[0.5999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.10299112 9.24281642 8.95995349 3.61650842 8.46059085 9.63354476\n",
      " 5.77238648 9.81101014] [38252.51518433] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[38252.51518433] [2.10299112 9.24281642 8.95995349 3.61650842 8.46059085 9.63354476\n",
      " 5.77238648 9.81101014] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.45449515 6.41719777 7.02404165 3.21488489 2.19329451 8.42931613\n",
      " 4.94438794 3.32288331] [44620.6255282] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[44620.6255282] [5.45449515 6.41719777 7.02404165 3.21488489 2.19329451 8.42931613\n",
      " 4.94438794 3.32288331] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1719 . [25592.75]\n",
      "[6.36561609 4.46092386 7.76467428 5.86205955 9.90076986 4.4588183\n",
      " 6.92587464 5.14131829] [61658.99897107] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[86153.80835399] [6.20428381 2.50037154 8.18003764 5.82915762 9.80571404 4.11784066\n",
      " 6.96757846 5.16175023] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4074 . [36539.75]\n",
      "[3.03349873 5.98991279 7.60201447 2.65350567 6.81253481 9.09042745\n",
      " 2.53521989 7.94049156] [45875.90841786] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80169.03990189] [2.72666018 2.50018198 8.38647033 2.63560126 6.75596192 8.53698218\n",
      " 2.80657449 7.90845974] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.25437912 4.24696162 3.97600304 7.53631715 2.00278013 7.8963462\n",
      " 2.3164338  8.83421963] [48670.73496768] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48670.73496768] [6.25437912 4.24696162 3.97600304 7.53631715 2.00278013 7.8963462\n",
      " 2.3164338  8.83421963] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.76717208 2.22148718 5.49317226 6.27369954 8.27637759 9.23078108\n",
      " 2.38469621 9.09560579] [73628.16218462] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73628.16218462] [2.76717208 2.22148718 5.49317226 6.27369954 8.27637759 9.23078108\n",
      " 2.38469621 9.09560579] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] [51020.46621753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51020.46621753] [4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1086 . [14610.]\n",
      "[6.7654802  3.66965415 2.85853634 3.91202373 9.98809675 6.17321435\n",
      " 9.28874301 5.78085487] [53852.17429214] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[67900.46934483] [6.68610321 2.50029211 3.21819948 3.91613198 9.94320301 6.05257541\n",
      " 9.30303901 5.78829129] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] [62247.78215649] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62247.78215649] [6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.45449515 6.41719777 7.02404165 3.21488489 2.19329451 8.42931613\n",
      " 4.94438794 3.32288331] [44620.6255282] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[44620.6255282] [5.45449515 6.41719777 7.02404165 3.21488489 2.19329451 8.42931613\n",
      " 4.94438794 3.32288331] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 77 . [69.75]\n",
      "[3.35861851 8.00191927 9.67182006 7.29808488 9.83597288 6.28172953\n",
      " 2.87220783 4.36908157] [41114.27338947] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[41189.76255545] [3.35620607 7.98019768 9.67813236 7.29539599 9.83322166 6.27477075\n",
      " 2.87290165 4.36914761] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.84788685 8.63168772 8.61044395 2.18168394 8.05187205 5.55607202\n",
      " 2.35807409 7.83784001] [40106.40173771] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[40106.40173771] [4.84788685 8.63168772 8.61044395 2.18168394 8.05187205 5.55607202\n",
      " 2.35807409 7.83784001] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.93118239 8.0127891  9.97709212 8.00819807 2.91740485 9.66763027\n",
      " 4.27111457 6.41234245] [38083.98579968] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[38083.98579968] [8.93118239 8.0127891  9.97709212 8.00819807 2.91740485 9.66763027\n",
      " 4.27111457 6.41234245] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] [62156.25871546] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62156.25871546] [6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1265 . [17762.25]\n",
      "[3.47162806 3.8712053  4.81450869 7.01926862 4.67299764 6.82779323\n",
      " 4.26650141 3.42291838] [59481.63868677] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76001.0797121] [3.37384521 2.50093669 5.18416925 6.99318825 4.62433765 6.61225641\n",
      " 4.34093368 3.41363071] tensor([[0.9994]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[6.31474184 7.9625008  9.62109694 5.82377057 6.71586524 9.89056473\n",
      " 6.83650778 5.31607151] [39798.29390913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39798.77475111] [6.31471054 7.96229158 9.62114224 5.82374877 6.71584865 9.8905481\n",
      " 6.83651392 5.31605701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 77 . [69.75]\n",
      "[3.35861851 8.00191927 9.67182006 7.29808488 9.83597288 6.28172953\n",
      " 2.87220783 4.36908157] [41114.27338947] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[41189.76255545] [3.35620607 7.98019768 9.67813236 7.29539599 9.83322166 6.27477075\n",
      " 2.87290165 4.36914761] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] [55912.15024953] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[55912.15024953] [5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.70381094 2.18843833 9.1430904  2.63586435 9.087634   8.09430626\n",
      " 6.82660793 3.75412987] [81694.78894574] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[81694.78894574] [8.70381094 2.18843833 9.1430904  2.63586435 9.087634   8.09430626\n",
      " 6.82660793 3.75412987] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1356 . [17577.5]\n",
      "[3.29835214 3.93847072 5.76595876 8.42154026 8.73202246 8.79435178\n",
      " 4.57508597 9.83259606] [57190.51116966] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73784.60493494] [3.19098009 2.50051314 6.10624844 8.37599599 8.71175908 8.61673394\n",
      " 4.66307057 9.82781261] tensor([[0.9908]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1891 . [20779.5]\n",
      "[8.56216044 4.33776831 7.93039701 4.37255955 9.41797969 8.24600758\n",
      " 2.72828151 6.3260847 ] [54330.92518972] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73864.27040014] [8.3740127  2.50073193 8.27868371 4.34985358 9.35672957 7.93902184\n",
      " 2.87419412 6.34320808] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2 . [1.25]\n",
      "[6.39951632 9.79564212 7.35208721 9.51407639 6.46764197 8.22852305\n",
      " 8.03919005 9.79319301] [35139.58532668] tensor([[0.9987]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35140.0357461] [6.39953456 9.79587122 7.3522088  9.5139997  6.46765067 8.22859748\n",
      " 8.0391128  9.79312224] tensor([[0.9987]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[3.0885825  7.34552638 5.19000697 2.65042012 8.70100458 8.68577093\n",
      " 7.85250398 8.18927875] [36754.46835563] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[60558.93500346] [2.87622199 4.05391678 6.35500247 2.66367772 8.6274635  8.47539558\n",
      " 7.87078521 8.13509009] tensor([[0.5995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.11829325 6.82476744 2.0357269  9.60730567 3.60323836 8.49364242\n",
      " 6.92712904 3.5485901 ] [32547.35501461] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32547.35501461] [2.11829325 6.82476744 2.0357269  9.60730567 3.60323836 8.49364242\n",
      " 6.92712904 3.5485901 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[3.07421164 7.20075127 6.37380909 4.27023187 5.28944986 7.86059427\n",
      " 6.30914519 7.51564167] [39995.00744805] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77762.37701118] [2.76774442 2.95511796 7.5796337  4.21882247 5.19621811 7.26734621\n",
      " 6.43259016 7.40405664] tensor([[0.5997]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 159 . [2980.5]\n",
      "[3.83671996 2.70671316 8.90347259 7.96412085 2.9236093  9.71053206\n",
      " 9.80305837 5.86719892] [80683.8276401] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83476.75578741] [3.8206675  2.50115551 8.93736124 7.95908789 2.91901061 9.68578389\n",
      " 9.81174733 5.86494581] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4678 . [37562.5]\n",
      "[5.51311011 6.26822205 3.42095021 9.23743387 7.05662242 6.82980833\n",
      " 8.57853598 3.86830712] [37201.05684387] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73697.37713184] [5.28248687 2.50100299 4.66199297 9.10326674 6.87299117 6.42460718\n",
      " 8.61616919 3.83847343] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 252 . [4381.]\n",
      "[5.05090265 2.80766466 7.25096646 4.20299825 7.8717653  6.32971129\n",
      " 3.56360566 6.14832627] [75729.16822194] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79810.2415559] [5.02491809 2.50008075 7.31691441 4.20042378 7.86201363 6.27707372\n",
      " 3.58109219 6.14961619] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2677 . [29165.5]\n",
      "[8.79607643 5.13182443 8.46903993 8.16844059 6.22613906 7.79248743\n",
      " 6.81633537 8.79534181] [51199.30745257] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79457.78083999] [8.55048124 2.50068352 8.93591744 8.0820881  6.16572697 7.38485138\n",
      " 6.93827011 8.76333707] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[4.20966833 4.82755058 8.33112372 6.05386772 6.45425962 7.42645223\n",
      " 9.66165679 9.32013025] [58138.74385741] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70422.04950154] [4.12457293 3.70307509 8.55875774 6.03085477 6.43021108 7.28248928\n",
      " 9.67803401 9.30537712] tensor([[0.6002]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.26853998 3.75434792 3.49514773 3.70263518 7.36137403 6.37198071\n",
      " 2.18045654 9.83002342] [54032.76959007] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54032.76959007] [5.26853998 3.75434792 3.49514773 3.70263518 7.36137403 6.37198071\n",
      " 2.18045654 9.83002342] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1995 . [27653.]\n",
      "[6.33425839 4.68945772 8.33101047 5.04150204 3.63316753 6.47734776\n",
      " 7.13844727 3.96118992] [60456.99656886] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[86692.14397357] [6.14815248 2.5009869  8.76385375 5.0152958  3.54939529 6.10070479\n",
      " 7.21658127 3.93941171] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2050 . [24182.5]\n",
      "[4.73444547 4.55713543 4.76768044 3.43126218 6.18119505 7.97143628\n",
      " 6.97046524 6.40215195] [51791.4423437] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[74743.13982339] [4.58418915 2.50048681 5.33481887 3.43348264 6.13000496 7.72655738\n",
      " 7.04947791 6.38425255] tensor([[0.6574]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] [57563.49352035] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[57563.49352035] [9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2 . [1.25]\n",
      "[5.49215417 8.26276766 6.21403859 8.44036831 9.6772564  6.78353181\n",
      " 2.86848029 5.2141351 ] [35955.10690946] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35955.68279589] [5.49213116 8.26255968 6.21428262 8.44030212 9.67720861 6.78346164\n",
      " 2.86848771 5.21412127] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] [48111.02279279] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48111.02279279] [3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.25]\n",
      "[6.412598   8.27427726 8.51503918 8.93291554 4.91323368 8.51247272\n",
      " 2.84247125 8.45886467] [36980.49000191] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36980.74777477] [6.41257457 8.27415206 8.51510444 8.93287619 4.9132342  8.51242521\n",
      " 2.84249406 8.45883361] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 567 . [11204.25]\n",
      "[5.21541801 3.2452491  8.89373312 5.15294394 7.57586859 4.11137217\n",
      " 7.01092286 2.74712375] [80603.74255278] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[91157.84573588] [5.15445712 2.50129336 9.0356892  5.14358123 7.53869467 3.97528832\n",
      " 7.03029887 2.7534869 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.11829325 6.82476744 2.0357269  9.60730567 3.60323836 8.49364242\n",
      " 6.92712904 3.5485901 ] [32547.35501461] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32547.35501461] [2.11829325 6.82476744 2.0357269  9.60730567 3.60323836 8.49364242\n",
      " 6.92712904 3.5485901 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2677 . [29165.5]\n",
      "[8.79607643 5.13182443 8.46903993 8.16844059 6.22613906 7.79248743\n",
      " 6.81633537 8.79534181] [51199.30745257] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79457.78083999] [8.55048124 2.50068352 8.93591744 8.0820881  6.16572697 7.38485138\n",
      " 6.93827011 8.76333707] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 371 . [5485.25]\n",
      "[9.52339449 2.92213104 6.26242017 3.20492704 4.98301278 7.68433721\n",
      " 7.19378052 5.73431281] [68257.8765478] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73446.6965008] [9.48584755 2.50013311 6.3565114  3.20611115 4.97133696 7.62514731\n",
      " 7.21393822 5.73130612] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.55884111 8.82054754 5.0221135  9.09558674 9.55597083 9.22706312\n",
      " 3.25523373 5.21691621] [34249.16780787] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[34249.16780787] [3.55884111 8.82054754 5.0221135  9.09558674 9.55597083 9.22706312\n",
      " 3.25523373 5.21691621] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[3.0885825  7.34552638 5.19000697 2.65042012 8.70100458 8.68577093\n",
      " 7.85250398 8.18927875] [36754.46835563] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[60548.78924981] [2.87629188 4.05488556 6.35475771 2.66367683 8.62748488 8.47549496\n",
      " 7.87075681 8.13509226] tensor([[0.6008]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.47555738 4.89731791 5.30721761 2.42642505 5.30376549 8.10282177\n",
      " 9.92544991 8.50215086] [50072.33684163] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[50072.33684163] [5.47555738 4.89731791 5.30721761 2.42642505 5.30376549 8.10282177\n",
      " 9.92544991 8.50215086] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2050 . [24182.5]\n",
      "[4.73444547 4.55713543 4.76768044 3.43126218 6.18119505 7.97143628\n",
      " 6.97046524 6.40215195] [51791.4423437] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[74743.13982339] [4.58418915 2.50048681 5.33481887 3.43348264 6.13000496 7.72655738\n",
      " 7.04947791 6.38425255] tensor([[0.6574]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 159 . [2980.5]\n",
      "[3.83671996 2.70671316 8.90347259 7.96412085 2.9236093  9.71053206\n",
      " 9.80305837 5.86719892] [80683.8276401] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83476.75578741] [3.8206675  2.50115551 8.93736124 7.95908789 2.91901061 9.68578389\n",
      " 9.81174733 5.86494581] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.95462855 5.20594564 2.04653061 7.76957186 8.74530383 7.54793829\n",
      " 5.16137886 7.01085736] [37657.61163288] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37657.61163288] [7.95462855 5.20594564 2.04653061 7.76957186 8.74530383 7.54793829\n",
      " 5.16137886 7.01085736] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1265 . [17762.25]\n",
      "[3.47162806 3.8712053  4.81450869 7.01926862 4.67299764 6.82779323\n",
      " 4.26650141 3.42291838] [59481.63868677] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76001.0797121] [3.37384521 2.50093669 5.18416925 6.99318825 4.62433765 6.61225641\n",
      " 4.34093368 3.41363071] tensor([[0.9994]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.76254164 2.40324077 8.77518014 3.82322874 4.85104019 4.60577037\n",
      " 8.11653639 8.55373399] [88072.41631271] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[88072.41631271] [8.76254164 2.40324077 8.77518014 3.82322874 4.85104019 4.60577037\n",
      " 8.11653639 8.55373399] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.51324278 3.07721551 6.85920372 6.88783709 9.21928215 6.05656858\n",
      " 5.77688879 2.11950605] [73219.8737354] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73219.8737354] [3.51324278 3.07721551 6.85920372 6.88783709 9.21928215 6.05656858\n",
      " 5.77688879 2.11950605] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 6 . [3.25]\n",
      "[8.00038394 8.01040703 8.39539127 3.58537272 3.25838512 8.3279503\n",
      " 8.18537281 9.91936961] [37856.44237771] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37860.44581604] [8.00020937 8.00900868 8.39595524 3.5853498  3.25841723 8.327774\n",
      " 8.18529484 9.91912628] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3 . [1.]\n",
      "[7.82541368 9.05357745 6.12543613 3.78607311 3.17592024 8.90417857\n",
      " 5.31863657 7.15969502] [36270.98908999] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36271.50883275] [7.82540673 9.05381069 6.12572508 3.78606955 3.17593848 8.90422755\n",
      " 5.31861605 7.15957332] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.06856866 2.21573269 6.34825617 7.88644084 7.55687063 9.58805763\n",
      " 3.48553571 3.46890728] [71667.30592196] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[71667.30592196] [7.06856866 2.21573269 6.34825617 7.88644084 7.55687063 9.58805763\n",
      " 3.48553571 3.46890728] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.76717208 2.22148718 5.49317226 6.27369954 8.27637759 9.23078108\n",
      " 2.38469621 9.09560579] [73628.16218462] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73628.16218462] [2.76717208 2.22148718 5.49317226 6.27369954 8.27637759 9.23078108\n",
      " 2.38469621 9.09560579] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] [62247.78215649] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62247.78215649] [6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.47555738 4.89731791 5.30721761 2.42642505 5.30376549 8.10282177\n",
      " 9.92544991 8.50215086] [50072.33684163] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[50072.33684163] [5.47555738 4.89731791 5.30721761 2.42642505 5.30376549 8.10282177\n",
      " 9.92544991 8.50215086] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5845 . [39176.75]\n",
      "[4.82380255 6.74118993 8.26776052 5.40919866 6.95306475 9.69790705\n",
      " 2.83948251 5.78381106] [42007.3568367] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[78925.36037793] [4.4090305  2.50080525 9.10555224 5.29160709 6.82691421 9.02145405\n",
      " 3.21750298 5.75721313] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1091 . [14402.75]\n",
      "[8.60608982 3.68830836 7.21414797 6.69336848 4.97587656 9.16413346\n",
      " 8.72876187 7.56794622] [61565.73731706] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75348.31019911] [8.50271414 2.50081071 7.44483387 6.67206426 4.95196328 9.02398316\n",
      " 8.78252976 7.55368131] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4678 . [37562.5]\n",
      "[5.51311011 6.26822205 3.42095021 9.23743387 7.05662242 6.82980833\n",
      " 8.57853598 3.86830712] [37201.05684387] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73697.37713184] [5.28248687 2.50100299 4.66199297 9.10326674 6.87299117 6.42460718\n",
      " 8.61616919 3.83847343] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5845 . [39176.75]\n",
      "[4.82380255 6.74118993 8.26776052 5.40919866 6.95306475 9.69790705\n",
      " 2.83948251 5.78381106] [42007.3568367] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[78925.36037793] [4.4090305  2.50080525 9.10555224 5.29160709 6.82691421 9.02145405\n",
      " 3.21750298 5.75721313] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.26853998 3.75434792 3.49514773 3.70263518 7.36137403 6.37198071\n",
      " 2.18045654 9.83002342] [54032.76959007] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54032.76959007] [5.26853998 3.75434792 3.49514773 3.70263518 7.36137403 6.37198071\n",
      " 2.18045654 9.83002342] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3171 . [33310.25]\n",
      "[3.21984115 5.39741914 3.06195252 3.71725886 3.17636821 6.49714444\n",
      " 4.97751651 3.937595  ] [43680.74102663] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75018.97540322] [3.03674118 2.50114166 4.06161644 3.72499718 3.08440253 6.05916178\n",
      " 5.09322235 3.87730039] tensor([[0.9956]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.07467226 3.47925257 5.06175521 2.20120157 8.43040333 6.00335154\n",
      " 2.08096464 3.39491605] [59236.75464846] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[59236.75464846] [8.07467226 3.47925257 5.06175521 2.20120157 8.43040333 6.00335154\n",
      " 2.08096464 3.39491605] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.91825354 8.84363622 8.66625149 2.02358779 9.74090145 9.86560545\n",
      " 7.37689289 9.83481264] [37937.64892269] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37937.64892269] [4.91825354 8.84363622 8.66625149 2.02358779 9.74090145 9.86560545\n",
      " 7.37689289 9.83481264] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.15196124 4.35963291 9.26497618 7.90888302 2.78174951 5.73667108\n",
      " 4.98554116 7.05954161] [68439.25495977] tensor([[0.9998]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[68439.25495977] [2.15196124 4.35963291 9.26497618 7.90888302 2.78174951 5.73667108\n",
      " 4.98554116 7.05954161] tensor([[0.9998]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5861 . [43859.]\n",
      "[5.71548708 7.10260945 8.71101024 8.82660091 8.47732381 7.75343561\n",
      " 6.88407201 6.98627806] [41374.41854346] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[84217.32274476] [5.31282262 2.50041561 9.56665646 8.59938069 8.29548261 7.05866631\n",
      " 7.02934684 6.96925644] tensor([[0.9988]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.75]\n",
      "[5.25904766 8.20173937 7.41872267 8.21652658 2.64033946 8.93704144\n",
      " 9.65310424 5.90079695] [37496.35977709] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37496.91669488] [5.25903568 8.20153484 7.41882727 8.21649783 2.64033065 8.93704104\n",
      " 9.6530819  5.90075993] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.26853998 3.75434792 3.49514773 3.70263518 7.36137403 6.37198071\n",
      " 2.18045654 9.83002342] [54032.76959007] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54032.76959007] [5.26853998 3.75434792 3.49514773 3.70263518 7.36137403 6.37198071\n",
      " 2.18045654 9.83002342] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1131 . [16295.5]\n",
      "[3.05074101 3.76269683 3.68850081 7.14244229 9.71011984 7.10126391\n",
      " 9.5367193  3.80073645] [56722.98247999] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72202.79328168] [2.97428316 2.50103601 4.04534168 7.12155259 9.6553422  6.98016349\n",
      " 9.5564438  3.81266731] tensor([[0.8226]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4149 . [38521.75]\n",
      "[3.42172594 6.20582209 7.96720695 7.5142045  9.50542259 8.79144984\n",
      " 7.7542459  6.3202216 ] [45569.15520989] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[82638.88563593] [3.13324333 2.50018078 8.70240983 7.38556041 9.3687013  8.36966258\n",
      " 7.87392027 6.339073  ] tensor([[0.7759]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] [51020.46621753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51020.46621753] [4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 23 . [18.75]\n",
      "[5.24784304 7.79964362 8.44100452 9.65821058 6.93777013 7.88230587\n",
      " 6.35395659 9.19617271] [38272.45312142] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[38294.79483637] [5.24724287 7.79301073 8.44317223 9.65721761 6.93759795 7.88129713\n",
      " 6.35391249 9.19563264] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 683 . [9764.25]\n",
      "[6.27364679 3.25691991 5.53904012 4.37568764 6.32528265 7.43092455\n",
      " 3.56693159 9.59640105] [63337.89400715] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72534.06517759] [6.21068804 2.50075104 5.72679977 4.37082007 6.31548088 7.31441212\n",
      " 3.61531123 9.58854767] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1373 . [15829.]\n",
      "[7.85420766 3.86778237 6.71424169 4.16686453 5.8950817  9.45835324\n",
      " 4.84018509 3.60578086] [57557.19353245] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72326.62754164] [7.72639672 2.50094133 7.00336129 4.15883132 5.84921675 9.2717296\n",
      " 4.94168218 3.60538879] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 510 . [10723.5]\n",
      "[4.33129396 3.20238894 9.66627147 3.24857185 8.74241455 5.19331968\n",
      " 9.87308596 9.479611  ] [82225.66874519] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[92480.14865241] [4.27558423 2.50111054 9.79098387 3.24456105 8.72231438 5.08591898\n",
      " 9.88233642 9.4808473 ] tensor([[0.9983]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 450 . [6165.5]\n",
      "[8.73286359 2.99412554 8.71650172 5.39791854 9.41658602 9.58566976\n",
      " 4.35316024 4.88773315] [66893.50596097] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72643.81225492] [8.6828641  2.50094283 8.79370624 5.38962954 9.39910275 9.51523977\n",
      " 4.39186969 4.89456629] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.24938549 7.1355691  9.60357587 6.03064032 9.55679646 9.94656893\n",
      " 5.29311738 3.4859656 ] [42781.92518807] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[42781.92518807] [2.24938549 7.1355691  9.60357587 6.03064032 9.55679646 9.94656893\n",
      " 5.29311738 3.4859656 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 567 . [11204.25]\n",
      "[5.21541801 3.2452491  8.89373312 5.15294394 7.57586859 4.11137217\n",
      " 7.01092286 2.74712375] [80603.74255278] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[91157.84573588] [5.15445712 2.50129336 9.0356892  5.14358123 7.53869467 3.97528832\n",
      " 7.03029887 2.7534869 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.25437912 4.24696162 3.97600304 7.53631715 2.00278013 7.8963462\n",
      " 2.3164338  8.83421963] [48670.73496768] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48670.73496768] [6.25437912 4.24696162 3.97600304 7.53631715 2.00278013 7.8963462\n",
      " 2.3164338  8.83421963] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] [56978.07774736] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56978.07774736] [5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 108 . [1759.5]\n",
      "[7.80140724 2.62842748 5.54328779 9.13336153 7.01419669 5.73058897\n",
      " 4.2462284  6.93044481] [71446.04961701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73105.28787059] [7.79091898 2.50056969 5.57366675 9.12978068 7.01033335 5.70911804\n",
      " 4.25315685 6.93010543] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[2.75783751 5.7397775  9.11131928 8.01095659 2.98231941 7.33500087\n",
      " 9.95023045 9.04886334] [52844.32521283] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[82024.91387107] [2.57153736 3.14654524 9.60012341 7.92731654 2.9353141  6.96308731\n",
      " 9.98357693 8.98047153] tensor([[0.6019]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[6.31474184 7.9625008  9.62109694 5.82377057 6.71586524 9.89056473\n",
      " 6.83650778 5.31607151] [39798.29390913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39798.77475111] [6.31471054 7.96229158 9.62114224 5.82374877 6.71584865 9.8905481\n",
      " 6.83651392 5.31605701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2957 . [30553.5]\n",
      "[7.73957652 5.27381196 4.09706971 7.71272833 8.64466748 5.33383564\n",
      " 7.07827247 8.3562118 ] [44337.97001957] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[74196.28999845] [7.53584592 2.50023646 4.92516517 7.64836211 8.55567279 4.9353844\n",
      " 7.12989014 8.33752625] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.31666012 3.86802621 2.32225016 2.61348146 6.03567236 4.31940999\n",
      " 5.86434536 9.52098839] [54154.08178909] tensor([[0.9984]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54154.08178909] [4.31666012 3.86802621 2.32225016 2.61348146 6.03567236 4.31940999\n",
      " 5.86434536 9.52098839] tensor([[0.9984]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.84788685 8.63168772 8.61044395 2.18168394 8.05187205 5.55607202\n",
      " 2.35807409 7.83784001] [40106.40173771] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[40106.40173771] [4.84788685 8.63168772 8.61044395 2.18168394 8.05187205 5.55607202\n",
      " 2.35807409 7.83784001] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 108 . [1759.5]\n",
      "[7.80140724 2.62842748 5.54328779 9.13336153 7.01419669 5.73058897\n",
      " 4.2462284  6.93044481] [71446.04961701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73105.28787059] [7.79091898 2.50056969 5.57366675 9.12978068 7.01033335 5.70911804\n",
      " 4.25315685 6.93010543] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.08199065 8.40358411 5.89640539 4.42759739 7.53155837 9.71729336\n",
      " 3.73004212 6.38113378] [36257.16387281] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36257.16387281] [6.08199065 8.40358411 5.89640539 4.42759739 7.53155837 9.71729336\n",
      " 3.73004212 6.38113378] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] [76347.89484793] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76347.89484793] [3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.41785327 8.26680725 4.55367652 4.91451848 5.77937036 9.39042502\n",
      " 2.42309088 4.50039664] [34848.44729995] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[34848.44729995] [2.41785327 8.26680725 4.55367652 4.91451848 5.77937036 9.39042502\n",
      " 2.42309088 4.50039664] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.09430523 2.42307718 2.93407938 6.63712449 4.52669832 3.66444724\n",
      " 4.90107397 5.32715955] [72301.36079866] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72301.36079866] [7.09430523 2.42307718 2.93407938 6.63712449 4.52669832 3.66444724\n",
      " 4.90107397 5.32715955] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.39264145 2.27191115 2.46288536 3.14119009 3.8611725  6.42414569\n",
      " 6.1764177  6.65003673] [70165.37270756] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70165.37270756] [4.39264145 2.27191115 2.46288536 3.14119009 3.8611725  6.42414569\n",
      " 6.1764177  6.65003673] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.52565651 7.8627154  7.70078007 3.22432224 9.65843035 8.85661078\n",
      " 3.97036025 9.9543257 ] [38241.89522611] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[38241.89522611] [5.52565651 7.8627154  7.70078007 3.22432224 9.65843035 8.85661078\n",
      " 3.97036025 9.9543257 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 104 . [1769.25]\n",
      "[8.76928857 2.62834603 6.056928   3.85091014 8.63540793 6.21728513\n",
      " 8.91450645 9.11925987] [73584.81342595] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75283.79397261] [8.75878349 2.50030961 6.08619488 3.85075649 8.63215529 6.20038259\n",
      " 8.91775257 9.11919723] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.96228433 8.94982755 8.14662728 4.20372935 6.1152242  7.86171944\n",
      " 6.43489365 6.10629442] [37935.81976833] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37935.81976833] [7.96228433 8.94982755 8.14662728 4.20372935 6.1152242  7.86171944\n",
      " 6.43489365 6.10629442] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1469 . [19019.75]\n",
      "[7.74386775 4.06369632 7.97899711 9.64484403 8.47690503 7.27085673\n",
      " 4.46140229 6.17626983] [58826.04635307] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76845.58820782] [7.60105443 2.50115209 8.26679681 9.58331308 8.42006882 7.01065153\n",
      " 4.55656417 6.18323364] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[2.75783751 5.7397775  9.11131928 8.01095659 2.98231941 7.33500087\n",
      " 9.95023045 9.04886334] [52844.32521283] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[82043.20306807] [2.57144039 3.14523113 9.60035146 7.9272827  2.93528918 6.9628943\n",
      " 9.98360747 8.98044935] tensor([[0.5995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 159 . [2980.5]\n",
      "[3.83671996 2.70671316 8.90347259 7.96412085 2.9236093  9.71053206\n",
      " 9.80305837 5.86719892] [80683.8276401] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83476.75578741] [3.8206675  2.50115551 8.93736124 7.95908789 2.91901061 9.68578389\n",
      " 9.81174733 5.86494581] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 567 . [11204.25]\n",
      "[5.21541801 3.2452491  8.89373312 5.15294394 7.57586859 4.11137217\n",
      " 7.01092286 2.74712375] [80603.74255278] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[91157.84573588] [5.15445712 2.50129336 9.0356892  5.14358123 7.53869467 3.97528832\n",
      " 7.03029887 2.7534869 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.01214383 5.83317797 7.79307746 7.0585404  2.17666415 9.6196165\n",
      " 4.56328074 2.63224649] [45315.34319785] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[45315.34319785] [9.01214383 5.83317797 7.79307746 7.0585404  2.17666415 9.6196165\n",
      " 4.56328074 2.63224649] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 275 . [3507.25]\n",
      "[6.27808473 2.7833712  2.74428348 8.30851092 7.19099635 8.49697235\n",
      " 3.67889578 3.3505978 ] [58333.65060116] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[61582.50648557] [6.25691176 2.50040108 2.82813357 8.30211265 7.18119196 8.46259521\n",
      " 3.69994873 3.35130496] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1867 . [23042.25]\n",
      "[6.80300303 4.44188674 5.09232451 4.49702205 8.23280156 6.85857552\n",
      " 8.44098143 8.16072244] [52991.87182831] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75256.21291677] [6.65600029 2.50037895 5.60269841 4.48811618 8.18085607 6.62444563\n",
      " 8.48420922 8.15272053] tensor([[0.9997]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 259 . [4265.25]\n",
      "[7.69025148 2.81017694 7.48039875 7.10897734 7.33196814 6.50889107\n",
      " 4.53468652 6.53750297] [73553.81889193] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77566.59143291] [7.66277899 2.50014193 7.54219935 7.10236787 7.32217783 6.45640536\n",
      " 4.55223879 6.53784903] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 653 . [12650.]\n",
      "[2.60843046 3.34646482 5.20140329 9.16694417 6.19210809 3.8501873\n",
      " 7.96071749 8.58640565] [71468.25033644] tensor([[0.9927]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83527.4686606] [2.55547781 2.50007983 5.42097381 9.14492984 6.1687054  3.71713303\n",
      " 7.97283499 8.57843442] tensor([[0.9487]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 59 . [58.5]\n",
      "[4.03335766 7.63764846 6.75125065 4.09463841 9.23440151 6.63295844\n",
      " 4.6558113  5.67161037] [39213.01698667] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39277.94990784] [4.0320016  7.62062666 6.76014853 4.09412373 9.23293555 6.62984053\n",
      " 4.65561004 5.6712365 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] [56978.07774736] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56978.07774736] [5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3790 . [32713.]\n",
      "[7.91940831 5.75010687 4.99891093 8.70989058 9.0463968  6.72622391\n",
      " 6.36021882 9.53906911] [41677.91626755] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73813.92491788] [7.66075245 2.50069649 5.89448827 8.59548572 8.96526736 6.28447347\n",
      " 6.46681529 9.5121552 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.55660753 5.66597905 2.14178692 8.16738261 6.53428476 7.1771633\n",
      " 3.07581495 2.23260327] [36805.85376187] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36805.85376187] [5.55660753 5.66597905 2.14178692 8.16738261 6.53428476 7.1771633\n",
      " 3.07581495 2.23260327] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] [57563.49352035] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[57563.49352035] [9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] [48111.02279279] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48111.02279279] [3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[4.20966833 4.82755058 8.33112372 6.05386772 6.45425962 7.42645223\n",
      " 9.66165679 9.32013025] [58138.74385741] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70422.04950154] [4.12457293 3.70307509 8.55875774 6.03085477 6.43021108 7.28248928\n",
      " 9.67803401 9.30537712] tensor([[0.6002]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.34722906 7.37824988 2.26491685 9.36257865 8.89383302 6.9966811\n",
      " 6.60915278 8.03253647] [29782.34066008] tensor([[0.9977]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[29782.34066008] [4.34722906 7.37824988 2.26491685 9.36257865 8.89383302 6.9966811\n",
      " 6.60915278 8.03253647] tensor([[0.9977]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 59 . [58.5]\n",
      "[4.03335766 7.63764846 6.75125065 4.09463841 9.23440151 6.63295844\n",
      " 4.6558113  5.67161037] [39213.01698667] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39277.94990784] [4.0320016  7.62062666 6.76014853 4.09412373 9.23293555 6.62984053\n",
      " 4.65561004 5.6712365 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[2.75783751 5.7397775  9.11131928 8.01095659 2.98231941 7.33500087\n",
      " 9.95023045 9.04886334] [52844.32521283] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[82043.20306807] [2.57144039 3.14523113 9.60035146 7.9272827  2.93528918 6.9628943\n",
      " 9.98360747 8.98044935] tensor([[0.5995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.39264145 2.27191115 2.46288536 3.14119009 3.8611725  6.42414569\n",
      " 6.1764177  6.65003673] [70165.37270756] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70165.37270756] [4.39264145 2.27191115 2.46288536 3.14119009 3.8611725  6.42414569\n",
      " 6.1764177  6.65003673] tensor([[0.9993]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1873 . [20208.5]\n",
      "[5.85864825 4.2843192  6.14918803 6.69545209 5.19060212 9.4347719\n",
      " 3.21813603 3.40114842] [53314.72121675] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72033.53855044] [5.7025641  2.50099281 6.55748854 6.65586859 5.13266552 9.17524245\n",
      " 3.37063917 3.39342084] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.41375525 4.91724    5.50447852 4.85866509 4.8783864  6.04473137\n",
      " 8.9356189  4.47636274] [54747.34296946] tensor([[0.9994]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54747.34296946] [2.41375525 4.91724    5.50447852 4.85866509 4.8783864  6.04473137\n",
      " 8.9356189  4.47636274] tensor([[0.9994]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[6.31474184 7.9625008  9.62109694 5.82377057 6.71586524 9.89056473\n",
      " 6.83650778 5.31607151] [39798.29390913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39798.77475111] [6.31471054 7.96229158 9.62114224 5.82374877 6.71584865 9.8905481\n",
      " 6.83651392 5.31605701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] [51020.46621753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51020.46621753] [4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.65964728 2.31993718 6.55140501 7.95313613 3.32003131 6.73966247\n",
      " 9.09835921 7.06541188] [80445.83183583] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80445.83183583] [7.65964728 2.31993718 6.55140501 7.95313613 3.32003131 6.73966247\n",
      " 9.09835921 7.06541188] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1719 . [25592.75]\n",
      "[6.36561609 4.46092386 7.76467428 5.86205955 9.90076986 4.4588183\n",
      " 6.92587464 5.14131829] [61658.99897107] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[86153.80835399] [6.20428381 2.50037154 8.18003764 5.82915762 9.80571404 4.11784066\n",
      " 6.96757846 5.16175023] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 104 . [1769.25]\n",
      "[8.76928857 2.62834603 6.056928   3.85091014 8.63540793 6.21728513\n",
      " 8.91450645 9.11925987] [73584.81342595] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75283.79397261] [8.75878349 2.50030961 6.08619488 3.85075649 8.63215529 6.20038259\n",
      " 8.91775257 9.11919723] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2650 . [27449.25]\n",
      "[7.97029877 4.9929493  4.98303034 7.82559806 4.23966158 7.0562222\n",
      " 5.97291621 8.46008862] [47199.32905665] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73681.04873915] [7.77100218 2.50062746 5.65517551 7.76426913 4.19589749 6.68247433\n",
      " 6.0866194  8.39974049] tensor([[0.9998]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.04238323 4.81812905 2.19057057 3.73409517 8.33735545 5.51629649\n",
      " 2.58606507 4.98470942] [42136.01669763] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[42136.01669763] [7.04238323 4.81812905 2.19057057 3.73409517 8.33735545 5.51629649\n",
      " 2.58606507 4.98470942] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.27814356 8.96585095 7.57448175 8.7051576  4.56471608 8.7318882\n",
      " 8.79337048 7.01202137] [36172.93601571] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36172.93601571] [4.27814356 8.96585095 7.57448175 8.7051576  4.56471608 8.7318882\n",
      " 8.79337048 7.01202137] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.64521175 5.78274711 5.15054132 2.47616186 5.29481872 8.75423079\n",
      " 9.1371161  8.90628269] [42158.80079566] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[42158.80079566] [7.64521175 5.78274711 5.15054132 2.47616186 5.29481872 8.75423079\n",
      " 9.1371161  8.90628269] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] [76347.89484793] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76347.89484793] [3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1719 . [25592.75]\n",
      "[6.36561609 4.46092386 7.76467428 5.86205955 9.90076986 4.4588183\n",
      " 6.92587464 5.14131829] [61658.99897107] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[86153.80835399] [6.20428381 2.50037154 8.18003764 5.82915762 9.80571404 4.11784066\n",
      " 6.96757846 5.16175023] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.14316892 7.45950784 8.23798354 9.26559455 2.14234778 9.39906092\n",
      " 7.67183702 4.93955909] [39531.53527268] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39531.53527268] [8.14316892 7.45950784 8.23798354 9.26559455 2.14234778 9.39906092\n",
      " 7.67183702 4.93955909] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.55660753 5.66597905 2.14178692 8.16738261 6.53428476 7.1771633\n",
      " 3.07581495 2.23260327] [36805.85376187] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36805.85376187] [5.55660753 5.66597905 2.14178692 8.16738261 6.53428476 7.1771633\n",
      " 3.07581495 2.23260327] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 318 . [5185.75]\n",
      "[6.06170208 2.87496314 6.90281982 2.70510471 7.12808567 6.70217093\n",
      " 3.84531715 3.59228077] [72725.73585299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77536.43766143] [6.02908693 2.50034578 6.9854691  2.70532951 7.11357809 6.63909737\n",
      " 3.86743006 3.59457598] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.09430523 2.42307718 2.93407938 6.63712449 4.52669832 3.66444724\n",
      " 4.90107397 5.32715955] [72301.36079866] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72301.36079866] [7.09430523 2.42307718 2.93407938 6.63712449 4.52669832 3.66444724\n",
      " 4.90107397 5.32715955] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.41785327 8.26680725 4.55367652 4.91451848 5.77937036 9.39042502\n",
      " 2.42309088 4.50039664] [34848.44729995] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[34848.44729995] [2.41785327 8.26680725 4.55367652 4.91451848 5.77937036 9.39042502\n",
      " 2.42309088 4.50039664] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] [57563.49352035] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[57563.49352035] [9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[6.31474184 7.9625008  9.62109694 5.82377057 6.71586524 9.89056473\n",
      " 6.83650778 5.31607151] [39798.29390913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39798.77475111] [6.31471054 7.96229158 9.62114224 5.82374877 6.71584865 9.8905481\n",
      " 6.83651392 5.31605701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 450 . [6165.5]\n",
      "[8.73286359 2.99412554 8.71650172 5.39791854 9.41658602 9.58566976\n",
      " 4.35316024 4.88773315] [66893.50596097] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72643.81225492] [8.6828641  2.50094283 8.79370624 5.38962954 9.39910275 9.51523977\n",
      " 4.39186969 4.89456629] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 450 . [6165.5]\n",
      "[8.73286359 2.99412554 8.71650172 5.39791854 9.41658602 9.58566976\n",
      " 4.35316024 4.88773315] [66893.50596097] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72643.81225492] [8.6828641  2.50094283 8.79370624 5.38962954 9.39910275 9.51523977\n",
      " 4.39186969 4.89456629] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1265 . [17762.25]\n",
      "[3.47162806 3.8712053  4.81450869 7.01926862 4.67299764 6.82779323\n",
      " 4.26650141 3.42291838] [59481.63868677] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76001.0797121] [3.37384521 2.50093669 5.18416925 6.99318825 4.62433765 6.61225641\n",
      " 4.34093368 3.41363071] tensor([[0.9994]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] [56321.8718417] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56321.8718417] [3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 5387 . [37682.25]\n",
      "[8.620305   6.52387304 3.88667836 4.19059542 8.64203901 6.0080067\n",
      " 6.58945111 9.07213468] [36424.78214145] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73797.40611016] [8.2988447  2.50065735 5.25747142 4.18335692 8.53224468 5.44966303\n",
      " 6.65618638 9.01797299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2382 . [31779.75]\n",
      "[3.15625135 5.03102599 4.70969599 3.06083945 9.29774736 4.79142794\n",
      " 8.05243392 4.79614511] [50944.89244003] tensor([[0.9979]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[81346.81495921] [2.99185225 2.500838   5.44728979 3.06624515 9.18228938 4.43359063\n",
      " 8.06538962 4.81102135] tensor([[0.8945]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2650 . [27449.25]\n",
      "[7.97029877 4.9929493  4.98303034 7.82559806 4.23966158 7.0562222\n",
      " 5.97291621 8.46008862] [47199.32905665] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73681.04873915] [7.77100218 2.50062746 5.65517551 7.76426913 4.19589749 6.68247433\n",
      " 6.0866194  8.39974049] tensor([[0.9998]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] [56978.07774736] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56978.07774736] [5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] [77040.73649469] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77040.73649469] [3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 683 . [9764.25]\n",
      "[6.27364679 3.25691991 5.53904012 4.37568764 6.32528265 7.43092455\n",
      " 3.56693159 9.59640105] [63337.89400715] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72534.06517759] [6.21068804 2.50075104 5.72679977 4.37082007 6.31548088 7.31441212\n",
      " 3.61531123 9.58854767] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 362 . [5015.5]\n",
      "[7.64918917 2.89758583 7.32706996 4.79547298 5.36945525 9.89016881\n",
      " 4.4248102  5.38032035] [67451.08429818] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72110.67916247] [7.61194163 2.50096885 7.40297655 4.79143355 5.36009426 9.83522697\n",
      " 4.45660878 5.37894365] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2327 . [28697.75]\n",
      "[9.73202703 4.90819071 9.87761547 7.90603198 3.3500978  6.60531857\n",
      " 4.96380549 5.17934609] [56561.03532644] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83960.06822663] [ 9.48856631  2.50077614 10.24666677  7.83109216  3.26328491  6.11363821\n",
      "  5.10285098  5.14714449] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3790 . [32713.]\n",
      "[7.91940831 5.75010687 4.99891093 8.70989058 9.0463968  6.72622391\n",
      " 6.36021882 9.53906911] [41677.91626755] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73813.92491788] [7.66075245 2.50069649 5.89448827 8.59548572 8.96526736 6.28447347\n",
      " 6.46681529 9.5121552 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.96228433 8.94982755 8.14662728 4.20372935 6.1152242  7.86171944\n",
      " 6.43489365 6.10629442] [37935.81976833] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37935.81976833] [7.96228433 8.94982755 8.14662728 4.20372935 6.1152242  7.86171944\n",
      " 6.43489365 6.10629442] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.75605699 6.36721186 6.21018579 2.31873533 9.23721144 8.4920594\n",
      " 7.48105592 9.17053736] [41224.72682987] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[41224.72682987] [6.75605699 6.36721186 6.21018579 2.31873533 9.23721144 8.4920594\n",
      " 7.48105592 9.17053736] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.51327434 3.49569823 8.17139805 2.00121097 8.00449541 7.89619011\n",
      " 6.9767483  8.15783429] [67923.80390554] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[67923.80390554] [6.51327434 3.49569823 8.17139805 2.00121097 8.00449541 7.89619011\n",
      " 6.9767483  8.15783429] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[4.20966833 4.82755058 8.33112372 6.05386772 6.45425962 7.42645223\n",
      " 9.66165679 9.32013025] [58138.74385741] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70435.7848922] [4.12448621 3.70193778 8.55897793 6.03083364 6.43018672 7.28234005\n",
      " 9.67805612 9.30536585] tensor([[0.5980]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] [62156.25871546] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62156.25871546] [6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 77 . [69.75]\n",
      "[3.35861851 8.00191927 9.67182006 7.29808488 9.83597288 6.28172953\n",
      " 2.87220783 4.36908157] [41114.27338947] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[41189.76255545] [3.35620607 7.98019768 9.67813236 7.29539599 9.83322166 6.27477075\n",
      " 2.87290165 4.36914761] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3825 . [35830.5]\n",
      "[4.14827727 5.9201598  7.34836891 9.24578232 4.57740199 9.50791698\n",
      " 7.98383891 4.3721734 ] [46498.18705846] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80603.6443331] [3.88774277 2.50114229 8.05284827 9.10398149 4.46322015 9.11396327\n",
      " 8.13186791 4.32635862] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1131 . [16295.5]\n",
      "[3.05074101 3.76269683 3.68850081 7.14244229 9.71011984 7.10126391\n",
      " 9.5367193  3.80073645] [56722.98247999] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72202.79328168] [2.97428316 2.50103601 4.04534168 7.12155259 9.6553422  6.98016349\n",
      " 9.5564438  3.81266731] tensor([[0.8226]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.76254164 2.40324077 8.77518014 3.82322874 4.85104019 4.60577037\n",
      " 8.11653639 8.55373399] [88072.41631271] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[88072.41631271] [8.76254164 2.40324077 8.77518014 3.82322874 4.85104019 4.60577037\n",
      " 8.11653639 8.55373399] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.76717208 2.22148718 5.49317226 6.27369954 8.27637759 9.23078108\n",
      " 2.38469621 9.09560579] [73628.16218462] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73628.16218462] [2.76717208 2.22148718 5.49317226 6.27369954 8.27637759 9.23078108\n",
      " 2.38469621 9.09560579] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.15196124 4.35963291 9.26497618 7.90888302 2.78174951 5.73667108\n",
      " 4.98554116 7.05954161] [68439.25495977] tensor([[0.9998]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[68439.25495977] [2.15196124 4.35963291 9.26497618 7.90888302 2.78174951 5.73667108\n",
      " 4.98554116 7.05954161] tensor([[0.9998]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2106 . [11860.25]\n",
      "[2.59348001 5.82705433 3.91710052 4.40979897 7.12855959 7.86119938\n",
      " 2.97554615 9.19828572] [40334.1653809] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51816.92577678] [2.50001483 4.40004064 4.46071125 4.39541826 7.11735659 7.67145465\n",
      " 3.06351698 9.16367294] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 6 . [115.25]\n",
      "[8.80520968 2.50792814 8.8845873  9.7151944  9.88507815 3.43088659\n",
      " 2.56398478 7.8957911 ] [83292.2198343] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83402.05658543] [8.80448928 2.50015615 8.88598183 9.71492461 9.88478118 3.42924493\n",
      " 2.56439454 7.89585466] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.06856866 2.21573269 6.34825617 7.88644084 7.55687063 9.58805763\n",
      " 3.48553571 3.46890728] [71667.30592196] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[71667.30592196] [7.06856866 2.21573269 6.34825617 7.88644084 7.55687063 9.58805763\n",
      " 3.48553571 3.46890728] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] [51020.46621753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51020.46621753] [4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 4197 . [40588.5]\n",
      "[4.20404871 6.23903807 9.53722911 4.87370122 5.62376644 8.01605349\n",
      " 3.50606934 3.87734483] [48474.36513678] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[86517.2008934] [ 3.85391216  2.50117071 10.18919504  4.7952754   5.47010527  7.30372936\n",
      "  3.7533133   3.86307765] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.95462855 5.20594564 2.04653061 7.76957186 8.74530383 7.54793829\n",
      " 5.16137886 7.01085736] [37657.61163288] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37657.61163288] [7.95462855 5.20594564 2.04653061 7.76957186 8.74530383 7.54793829\n",
      " 5.16137886 7.01085736] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3790 . [32713.]\n",
      "[7.91940831 5.75010687 4.99891093 8.70989058 9.0463968  6.72622391\n",
      " 6.36021882 9.53906911] [41677.91626755] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73813.92491788] [7.66075245 2.50069649 5.89448827 8.59548572 8.96526736 6.28447347\n",
      " 6.46681529 9.5121552 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5845 . [39176.75]\n",
      "[4.82380255 6.74118993 8.26776052 5.40919866 6.95306475 9.69790705\n",
      " 2.83948251 5.78381106] [42007.3568367] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[78925.36037793] [4.4090305  2.50080525 9.10555224 5.29160709 6.82691421 9.02145405\n",
      " 3.21750298 5.75721313] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.01214383 5.83317797 7.79307746 7.0585404  2.17666415 9.6196165\n",
      " 4.56328074 2.63224649] [45315.34319785] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[45315.34319785] [9.01214383 5.83317797 7.79307746 7.0585404  2.17666415 9.6196165\n",
      " 4.56328074 2.63224649] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] [51020.46621753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51020.46621753] [4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3790 . [32713.]\n",
      "[7.91940831 5.75010687 4.99891093 8.70989058 9.0463968  6.72622391\n",
      " 6.36021882 9.53906911] [41677.91626755] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73813.92491788] [7.66075245 2.50069649 5.89448827 8.59548572 8.96526736 6.28447347\n",
      " 6.46681529 9.5121552 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[6.31474184 7.9625008  9.62109694 5.82377057 6.71586524 9.89056473\n",
      " 6.83650778 5.31607151] [39798.29390913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39798.77475111] [6.31471054 7.96229158 9.62114224 5.82374877 6.71584865 9.8905481\n",
      " 6.83651392 5.31605701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4074 . [36539.75]\n",
      "[3.03349873 5.98991279 7.60201447 2.65350567 6.81253481 9.09042745\n",
      " 2.53521989 7.94049156] [45875.90841786] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80169.03990189] [2.72666018 2.50018198 8.38647033 2.63560126 6.75596192 8.53698218\n",
      " 2.80657449 7.90845974] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.4666134  4.14682708 2.14685041 2.35237228 2.33405622 9.83755059\n",
      " 4.03148476 3.2407511 ] [43520.70012078] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[43520.70012078] [9.4666134  4.14682708 2.14685041 2.35237228 2.33405622 9.83755059\n",
      " 4.03148476 3.2407511 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.34722906 7.37824988 2.26491685 9.36257865 8.89383302 6.9966811\n",
      " 6.60915278 8.03253647] [29782.34066008] tensor([[0.9977]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[29782.34066008] [4.34722906 7.37824988 2.26491685 9.36257865 8.89383302 6.9966811\n",
      " 6.60915278 8.03253647] tensor([[0.9977]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.25]\n",
      "[6.412598   8.27427726 8.51503918 8.93291554 4.91323368 8.51247272\n",
      " 2.84247125 8.45886467] [36980.49000191] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36980.74777477] [6.41257457 8.27415206 8.51510444 8.93287619 4.9132342  8.51242521\n",
      " 2.84249406 8.45883361] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 33 . [589.]\n",
      "[7.80505753 2.54229604 8.5460933  4.07310714 7.07032581 7.27334893\n",
      " 7.69894332 2.86202971] [79938.5584868] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80491.01842909] [7.80135161 2.50093473 8.55341793 4.07285531 7.06855024 7.26715518\n",
      " 7.70070574 2.86235606] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.85340823 9.26563236 7.95923307 3.64831335 9.36963147 7.99682817\n",
      " 9.43597667 6.95061809] [36138.82304137] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36138.82304137] [9.85340823 9.26563236 7.95923307 3.64831335 9.36963147 7.99682817\n",
      " 9.43597667 6.95061809] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "samples = filtered_df.iloc[np.random.choice(len(filtered_df), 197), :8]\n",
    "for i in range(len(samples)):\n",
    "    X0 = np.array(samples.iloc[i])\n",
    "    result = coordinateAscentQuad(classif, ridge, X0, confidence = .6)\n",
    "    print(X0, ridge.predict(poly.fit_transform([X0])), classif(torch.from_numpy(poly.fit_transform([X0]))))\n",
    "    print(ridge.predict(poly.fit_transform([result])), result, classif(torch.from_numpy(poly.fit_transform([result]))))\n",
    "    results.append((X0, result, ridge.predict(poly.fit_transform([result])), ridge.predict(poly.fit_transform([result]) - ridge.predict(poly.fit_transform([X0])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bfb1148b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([4.33129396, 3.20238894, 9.66627147, 3.24857185, 8.74241455,\n",
       "         5.19331968, 9.87308596, 9.479611  ]),\n",
       "  array([4.27558423, 2.50111054, 9.79098387, 3.24456105, 8.72231438,\n",
       "         5.08591898, 9.88233642, 9.4808473 ]),\n",
       "  array([92480.14865241])),\n",
       " (array([3.84330328, 3.11903088, 8.63367165, 8.88974916, 8.81972552,\n",
       "         3.69938965, 8.75334237, 8.74292895]),\n",
       "  array([3.79774661, 2.50143278, 8.75329661, 8.87230654, 8.79869793,\n",
       "         3.59618521, 8.76162157, 8.74398984]),\n",
       "  array([92073.68628317])),\n",
       " (array([5.21541801, 3.2452491 , 8.89373312, 5.15294394, 7.57586859,\n",
       "         4.11137217, 7.01092286, 2.74712375]),\n",
       "  array([5.15445712, 2.50129336, 9.0356892 , 5.14358123, 7.53869467,\n",
       "         3.97528832, 7.03029887, 2.7534869 ]),\n",
       "  array([91157.84573588])),\n",
       " (array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([88072.41631271])),\n",
       " (array([3.20978778, 5.61620938, 6.28397452, 7.22049742, 4.15747764,\n",
       "         5.30598582, 7.07260903, 9.02065844]),\n",
       "  array([2.99928303, 2.50125721, 7.08605427, 7.14709699, 4.09142989,\n",
       "         4.78534027, 7.13051966, 8.94938591]),\n",
       "  array([87109.20575545])),\n",
       " (array([3.20978778, 5.61620938, 6.28397452, 7.22049742, 4.15747764,\n",
       "         5.30598582, 7.07260903, 9.02065844]),\n",
       "  array([2.99928303, 2.50125721, 7.08605427, 7.14709699, 4.09142989,\n",
       "         4.78534027, 7.13051966, 8.94938591]),\n",
       "  array([87109.20575545])),\n",
       " (array([6.33425839, 4.68945772, 8.33101047, 5.04150204, 3.63316753,\n",
       "         6.47734776, 7.13844727, 3.96118992]),\n",
       "  array([6.14815248, 2.5009869 , 8.76385375, 5.0152958 , 3.54939529,\n",
       "         6.10070479, 7.21658127, 3.93941171]),\n",
       "  array([86692.14397357])),\n",
       " (array([6.33425839, 4.68945772, 8.33101047, 5.04150204, 3.63316753,\n",
       "         6.47734776, 7.13844727, 3.96118992]),\n",
       "  array([6.14815248, 2.5009869 , 8.76385375, 5.0152958 , 3.54939529,\n",
       "         6.10070479, 7.21658127, 3.93941171]),\n",
       "  array([86692.14397357])),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([3.0115428 , 2.50048433, 6.35845087, 7.17251176, 5.43026482,\n",
       "         3.84269922, 4.59815405, 2.70692833]),\n",
       "  array([85849.063644])),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([3.0115428 , 2.50048433, 6.35845087, 7.17251176, 5.43026482,\n",
       "         3.84269922, 4.59815405, 2.70692833]),\n",
       "  array([85849.063644])),\n",
       " (array([2.32452262, 2.58871554, 9.32749721, 9.99315489, 4.52452962,\n",
       "         7.02169385, 4.2840132 , 2.97129558]),\n",
       "  array([2.32452262, 2.58871554, 9.32749721, 9.99315489, 4.52452962,\n",
       "         7.02169385, 4.2840132 , 2.97129558]),\n",
       "  array([85001.71772456])),\n",
       " (array([5.5656446 , 4.48493532, 9.23656697, 7.38481998, 7.2770088 ,\n",
       "         6.54463189, 2.93160599, 9.79820983]),\n",
       "  array([5.38522212, 2.50116293, 9.58608649, 7.32436804, 7.23510953,\n",
       "         6.1632929 , 3.05416052, 9.78650457]),\n",
       "  array([84335.20699449])),\n",
       " (array([5.5656446 , 4.48493532, 9.23656697, 7.38481998, 7.2770088 ,\n",
       "         6.54463189, 2.93160599, 9.79820983]),\n",
       "  array([5.38522212, 2.50116293, 9.58608649, 7.32436804, 7.23510953,\n",
       "         6.1632929 , 3.05416052, 9.78650457]),\n",
       "  array([84335.20699449])),\n",
       " (array([9.73202703, 4.90819071, 9.87761547, 7.90603198, 3.3500978 ,\n",
       "         6.60531857, 4.96380549, 5.17934609]),\n",
       "  array([ 9.48856631,  2.50077614, 10.24666677,  7.83109216,  3.26328491,\n",
       "          6.11363821,  5.10285098,  5.14714449]),\n",
       "  array([83960.06822663])),\n",
       " (array([2.60843046, 3.34646482, 5.20140329, 9.16694417, 6.19210809,\n",
       "         3.8501873 , 7.96071749, 8.58640565]),\n",
       "  array([2.55547781, 2.50007983, 5.42097381, 9.14492984, 6.1687054 ,\n",
       "         3.71713303, 7.97283499, 8.57843442]),\n",
       "  array([83527.4686606])),\n",
       " (array([2.60843046, 3.34646482, 5.20140329, 9.16694417, 6.19210809,\n",
       "         3.8501873 , 7.96071749, 8.58640565]),\n",
       "  array([2.55547781, 2.50007983, 5.42097381, 9.14492984, 6.1687054 ,\n",
       "         3.71713303, 7.97283499, 8.57843442]),\n",
       "  array([83527.4686606])),\n",
       " (array([7.90470929, 6.3330749 , 8.19267455, 4.62380641, 8.59141207,\n",
       "         7.24683375, 9.46541789, 6.35831765]),\n",
       "  array([7.56371575, 2.5003345 , 8.95474064, 4.57663979, 8.43036026,\n",
       "         6.73817527, 9.50830089, 6.35927884]),\n",
       "  array([83059.71922682])),\n",
       " (array([4.0997709 , 4.72308756, 6.04574065, 4.31566137, 4.58856511,\n",
       "         5.25662271, 7.65743655, 6.56904682]),\n",
       "  array([3.9556936 , 2.68411005, 6.57356225, 4.30470009, 4.52693413,\n",
       "         4.93023515, 7.69412152, 6.54061192]),\n",
       "  array([82671.33842436])),\n",
       " (array([4.0997709 , 4.72308756, 6.04574065, 4.31566137, 4.58856511,\n",
       "         5.25662271, 7.65743655, 6.56904682]),\n",
       "  array([3.9556936 , 2.68411005, 6.57356225, 4.30470009, 4.52693413,\n",
       "         4.93023515, 7.69412152, 6.54061192]),\n",
       "  array([82671.33842436])),\n",
       " (array([2.75783751, 5.7397775 , 9.11131928, 8.01095659, 2.98231941,\n",
       "         7.33500087, 9.95023045, 9.04886334]),\n",
       "  array([2.57144039, 3.14523113, 9.60035146, 7.9272827 , 2.93528918,\n",
       "         6.9628943 , 9.98360747, 8.98044935]),\n",
       "  array([82043.20306807])),\n",
       " (array([2.75783751, 5.7397775 , 9.11131928, 8.01095659, 2.98231941,\n",
       "         7.33500087, 9.95023045, 9.04886334]),\n",
       "  array([2.57153736, 3.14654524, 9.60012341, 7.92731654, 2.9353141 ,\n",
       "         6.96308731, 9.98357693, 8.98047153]),\n",
       "  array([82024.91387107])),\n",
       " (array([2.75783751, 5.7397775 , 9.11131928, 8.01095659, 2.98231941,\n",
       "         7.33500087, 9.95023045, 9.04886334]),\n",
       "  array([2.57153736, 3.14654524, 9.60012341, 7.92731654, 2.9353141 ,\n",
       "         6.96308731, 9.98357693, 8.98047153]),\n",
       "  array([82024.91387107])),\n",
       " (array([7.00933451, 6.45751096, 8.41870936, 7.93664641, 6.46337112,\n",
       "         8.07023648, 6.12427831, 5.59915807]),\n",
       "  array([6.64309565, 2.50003638, 9.1612619 , 7.78451669, 6.31041073,\n",
       "         7.43910579, 6.31380175, 5.56672223]),\n",
       "  array([81722.6407443])),\n",
       " (array([7.00933451, 6.45751096, 8.41870936, 7.93664641, 6.46337112,\n",
       "         8.07023648, 6.12427831, 5.59915807]),\n",
       "  array([6.64309565, 2.50003638, 9.1612619 , 7.78451669, 6.31041073,\n",
       "         7.43910579, 6.31380175, 5.56672223]),\n",
       "  array([81722.6407443])),\n",
       " (array([8.70381094, 2.18843833, 9.1430904 , 2.63586435, 9.087634  ,\n",
       "         8.09430626, 6.82660793, 3.75412987]),\n",
       "  array([8.70381094, 2.18843833, 9.1430904 , 2.63586435, 9.087634  ,\n",
       "         8.09430626, 6.82660793, 3.75412987]),\n",
       "  array([81694.78894574])),\n",
       " (array([6.46193032, 2.46136168, 6.21853628, 5.25788148, 7.9013281 ,\n",
       "         4.56285222, 9.38669684, 4.9114767 ]),\n",
       "  array([6.46193032, 2.46136168, 6.21853628, 5.25788148, 7.9013281 ,\n",
       "         4.56285222, 9.38669684, 4.9114767 ]),\n",
       "  array([81689.71403075])),\n",
       " (array([6.46193032, 2.46136168, 6.21853628, 5.25788148, 7.9013281 ,\n",
       "         4.56285222, 9.38669684, 4.9114767 ]),\n",
       "  array([6.46193032, 2.46136168, 6.21853628, 5.25788148, 7.9013281 ,\n",
       "         4.56285222, 9.38669684, 4.9114767 ]),\n",
       "  array([81689.71403075])),\n",
       " (array([8.04243762, 6.54567728, 9.72284694, 2.59465914, 4.73874635,\n",
       "         8.58703844, 3.40612364, 8.84626268]),\n",
       "  array([ 7.59490922,  2.50051912, 10.39065841,  2.57255918,  4.68136596,\n",
       "          7.79869293,  3.71574977,  8.75514366]),\n",
       "  array([81600.37690362])),\n",
       " (array([8.04243762, 6.54567728, 9.72284694, 2.59465914, 4.73874635,\n",
       "         8.58703844, 3.40612364, 8.84626268]),\n",
       "  array([ 7.59490922,  2.50051912, 10.39065841,  2.57255918,  4.68136596,\n",
       "          7.79869293,  3.71574977,  8.75514366]),\n",
       "  array([81600.37690362])),\n",
       " (array([3.15625135, 5.03102599, 4.70969599, 3.06083945, 9.29774736,\n",
       "         4.79142794, 8.05243392, 4.79614511]),\n",
       "  array([2.99185225, 2.500838  , 5.44728979, 3.06624515, 9.18228938,\n",
       "         4.43359063, 8.06538962, 4.81102135]),\n",
       "  array([81346.81495921])),\n",
       " (array([3.25988679, 4.16643163, 6.11047137, 9.05088628, 3.3246417 ,\n",
       "         7.48755927, 9.4141829 , 8.73158176]),\n",
       "  array([3.14989442, 2.50049608, 6.50069441, 9.00313814, 3.29755389,\n",
       "         7.27971736, 9.45466984, 8.69606535]),\n",
       "  array([80838.9947756])),\n",
       " (array([2.18813213, 2.9292535 , 9.03466641, 7.78791587, 3.77742236,\n",
       "         6.61714789, 2.36987329, 4.4287817 ]),\n",
       "  array([2.18813213, 2.9292535 , 9.03466641, 7.78791587, 3.77742236,\n",
       "         6.61714789, 2.36987329, 4.4287817 ]),\n",
       "  array([80740.67770982])),\n",
       " (array([2.18813213, 2.9292535 , 9.03466641, 7.78791587, 3.77742236,\n",
       "         6.61714789, 2.36987329, 4.4287817 ]),\n",
       "  array([2.18813213, 2.9292535 , 9.03466641, 7.78791587, 3.77742236,\n",
       "         6.61714789, 2.36987329, 4.4287817 ]),\n",
       "  array([80740.67770982])),\n",
       " (array([7.80505753, 2.54229604, 8.5460933 , 4.07310714, 7.07032581,\n",
       "         7.27334893, 7.69894332, 2.86202971]),\n",
       "  array([7.80135161, 2.50093473, 8.55341793, 4.07285531, 7.06855024,\n",
       "         7.26715518, 7.70070574, 2.86235606]),\n",
       "  array([80491.01842909])),\n",
       " (array([4.17974297, 2.25156054, 7.04646572, 8.54041952, 8.84656144,\n",
       "         8.72235424, 8.18360111, 6.28557734]),\n",
       "  array([4.17974297, 2.25156054, 7.04646572, 8.54041952, 8.84656144,\n",
       "         8.72235424, 8.18360111, 6.28557734]),\n",
       "  array([80304.97727485])),\n",
       " (array([5.05090265, 2.80766466, 7.25096646, 4.20299825, 7.8717653 ,\n",
       "         6.32971129, 3.56360566, 6.14832627]),\n",
       "  array([5.02491809, 2.50008075, 7.31691441, 4.20042378, 7.86201363,\n",
       "         6.27707372, 3.58109219, 6.14961619]),\n",
       "  array([79810.2415559])),\n",
       " (array([5.05090265, 2.80766466, 7.25096646, 4.20299825, 7.8717653 ,\n",
       "         6.32971129, 3.56360566, 6.14832627]),\n",
       "  array([5.02491809, 2.50008075, 7.31691441, 4.20042378, 7.86201363,\n",
       "         6.27707372, 3.58109219, 6.14961619]),\n",
       "  array([79810.2415559])),\n",
       " (array([7.15585233, 4.56683534, 8.60808435, 9.35819159, 7.10463724,\n",
       "         8.48446358, 7.18576991, 8.61969735]),\n",
       "  array([6.97333329, 2.50032633, 8.95698646, 9.2785242 , 7.05667578,\n",
       "         8.19680057, 7.28481466, 8.60646599]),\n",
       "  array([79273.97608407])),\n",
       " (array([7.15585233, 4.56683534, 8.60808435, 9.35819159, 7.10463724,\n",
       "         8.48446358, 7.18576991, 8.61969735]),\n",
       "  array([6.97333329, 2.50032633, 8.95698646, 9.2785242 , 7.05667578,\n",
       "         8.19680057, 7.28481466, 8.60646599]),\n",
       "  array([79273.97608407])),\n",
       " (array([3.41457626, 2.88066793, 9.95030403, 6.65990444, 5.80259326,\n",
       "         7.74979651, 2.11154534, 2.27863421]),\n",
       "  array([3.41457626, 2.88066793, 9.95030403, 6.65990444, 5.80259326,\n",
       "         7.74979651, 2.11154534, 2.27863421]),\n",
       "  array([78563.30881439])),\n",
       " (array([3.41457626, 2.88066793, 9.95030403, 6.65990444, 5.80259326,\n",
       "         7.74979651, 2.11154534, 2.27863421]),\n",
       "  array([3.41457626, 2.88066793, 9.95030403, 6.65990444, 5.80259326,\n",
       "         7.74979651, 2.11154534, 2.27863421]),\n",
       "  array([78563.30881439])),\n",
       " (array([3.41457626, 2.88066793, 9.95030403, 6.65990444, 5.80259326,\n",
       "         7.74979651, 2.11154534, 2.27863421]),\n",
       "  array([3.41457626, 2.88066793, 9.95030403, 6.65990444, 5.80259326,\n",
       "         7.74979651, 2.11154534, 2.27863421]),\n",
       "  array([78563.30881439])),\n",
       " (array([3.07421164, 7.20075127, 6.37380909, 4.27023187, 5.28944986,\n",
       "         7.86059427, 6.30914519, 7.51564167]),\n",
       "  array([2.76774442, 2.95511796, 7.5796337 , 4.21882247, 5.19621811,\n",
       "         7.26734621, 6.43259016, 7.40405664]),\n",
       "  array([77762.37701118])),\n",
       " (array([3.07421164, 7.20075127, 6.37380909, 4.27023187, 5.28944986,\n",
       "         7.86059427, 6.30914519, 7.51564167]),\n",
       "  array([2.76783816, 2.95634797, 7.57937221, 4.2188326 , 5.19624537,\n",
       "         7.26752916, 6.43253797, 7.40406628]),\n",
       "  array([77746.1031659])),\n",
       " (array([8.25075288, 4.11769335, 9.33777293, 4.56571548, 7.51040523,\n",
       "         9.06297006, 4.95755156, 8.70316981]),\n",
       "  array([8.08819932, 2.50027861, 9.58928319, 4.54283703, 7.47824847,\n",
       "         8.81591196, 5.06796176, 8.69968243]),\n",
       "  array([77677.78545597])),\n",
       " (array([7.69025148, 2.81017694, 7.48039875, 7.10897734, 7.33196814,\n",
       "         6.50889107, 4.53468652, 6.53750297]),\n",
       "  array([7.66277899, 2.50014193, 7.54219935, 7.10236787, 7.32217783,\n",
       "         6.45640536, 4.55223879, 6.53784903]),\n",
       "  array([77566.59143291])),\n",
       " (array([6.06170208, 2.87496314, 6.90281982, 2.70510471, 7.12808567,\n",
       "         6.70217093, 3.84531715, 3.59228077]),\n",
       "  array([6.02908693, 2.50034578, 6.9854691 , 2.70532951, 7.11357809,\n",
       "         6.63909737, 3.86743006, 3.59457598]),\n",
       "  array([77536.43766143])),\n",
       " (array([4.27708762, 4.11694671, 5.97936026, 7.57877923, 5.32415722,\n",
       "         7.90499279, 6.21599661, 5.62194636]),\n",
       "  array([4.15647467, 2.50040924, 6.36240666, 7.54028077, 5.27854047,\n",
       "         7.68299347, 6.29358925, 5.60844755]),\n",
       "  array([77518.29885058])),\n",
       " (array([4.27708762, 4.11694671, 5.97936026, 7.57877923, 5.32415722,\n",
       "         7.90499279, 6.21599661, 5.62194636]),\n",
       "  array([4.15647467, 2.50040924, 6.36240666, 7.54028077, 5.27854047,\n",
       "         7.68299347, 6.29358925, 5.60844755]),\n",
       "  array([77518.29885058])),\n",
       " (array([9.25067508, 3.96535082, 6.35253056, 7.82715472, 7.14608988,\n",
       "         4.61303537, 3.0952779 , 3.68570653]),\n",
       "  array([9.11807496, 2.50097351, 6.6961807 , 7.79061097, 7.07535637,\n",
       "         4.31546944, 3.17590308, 3.69003864]),\n",
       "  array([77505.19115906])),\n",
       " (array([7.83616152, 4.12446818, 8.26146515, 7.8197602 , 2.56544452,\n",
       "         9.52279921, 6.45425932, 4.03578958]),\n",
       "  array([7.68660329, 2.50053863, 8.54160659, 7.77540492, 2.51828605,\n",
       "         9.28683399, 6.56177822, 4.01286953]),\n",
       "  array([77461.87551889])),\n",
       " (array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([77040.73649469])),\n",
       " (array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([77040.73649469])),\n",
       " (array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([77040.73649469])),\n",
       " (array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([77040.73649469])),\n",
       " (array([3.38506849, 3.75294058, 9.5478579 , 2.41258871, 4.68348589,\n",
       "         4.7158803 , 3.87426201, 6.65679341]),\n",
       "  array([3.38506849, 3.75294058, 9.5478579 , 2.41258871, 4.68348589,\n",
       "         4.7158803 , 3.87426201, 6.65679341]),\n",
       "  array([76954.71047766])),\n",
       " (array([7.74386775, 4.06369632, 7.97899711, 9.64484403, 8.47690503,\n",
       "         7.27085673, 4.46140229, 6.17626983]),\n",
       "  array([7.60105443, 2.50115209, 8.26679681, 9.58331308, 8.42006882,\n",
       "         7.01065153, 4.55656417, 6.18323364]),\n",
       "  array([76845.58820782])),\n",
       " (array([7.74386775, 4.06369632, 7.97899711, 9.64484403, 8.47690503,\n",
       "         7.27085673, 4.46140229, 6.17626983]),\n",
       "  array([7.60105443, 2.50115209, 8.26679681, 9.58331308, 8.42006882,\n",
       "         7.01065153, 4.55656417, 6.18323364]),\n",
       "  array([76845.58820782])),\n",
       " (array([8.44049955, 2.1746643 , 5.92928775, 4.05607782, 8.02181382,\n",
       "         7.98377955, 9.71931208, 2.91415316]),\n",
       "  array([8.44049955, 2.1746643 , 5.92928775, 4.05607782, 8.02181382,\n",
       "         7.98377955, 9.71931208, 2.91415316]),\n",
       "  array([76711.30682215])),\n",
       " (array([8.44049955, 2.1746643 , 5.92928775, 4.05607782, 8.02181382,\n",
       "         7.98377955, 9.71931208, 2.91415316]),\n",
       "  array([8.44049955, 2.1746643 , 5.92928775, 4.05607782, 8.02181382,\n",
       "         7.98377955, 9.71931208, 2.91415316]),\n",
       "  array([76711.30682215])),\n",
       " (array([3.44278251, 2.09204241, 3.67034471, 5.5405317 , 3.84293424,\n",
       "         8.57451087, 9.26924851, 2.9502659 ]),\n",
       "  array([3.44278251, 2.09204241, 3.67034471, 5.5405317 , 3.84293424,\n",
       "         8.57451087, 9.26924851, 2.9502659 ]),\n",
       "  array([76347.89484793])),\n",
       " (array([3.47162806, 3.8712053 , 4.81450869, 7.01926862, 4.67299764,\n",
       "         6.82779323, 4.26650141, 3.42291838]),\n",
       "  array([3.37384521, 2.50093669, 5.18416925, 6.99318825, 4.62433765,\n",
       "         6.61225641, 4.34093368, 3.41363071]),\n",
       "  array([76001.0797121])),\n",
       " (array([3.47162806, 3.8712053 , 4.81450869, 7.01926862, 4.67299764,\n",
       "         6.82779323, 4.26650141, 3.42291838]),\n",
       "  array([3.37384521, 2.50093669, 5.18416925, 6.99318825, 4.62433765,\n",
       "         6.61225641, 4.34093368, 3.41363071]),\n",
       "  array([76001.0797121])),\n",
       " (array([3.071609  , 4.24563298, 5.1245792 , 7.19735674, 6.06970858,\n",
       "         7.5685513 , 4.64635842, 9.32825589]),\n",
       "  array([2.94834358, 2.50122035, 5.58430555, 7.15773578, 6.04590243,\n",
       "         7.32269498, 4.7378718 , 9.30423299]),\n",
       "  array([75603.91310701])),\n",
       " (array([8.60608982, 3.68830836, 7.21414797, 6.69336848, 4.97587656,\n",
       "         9.16413346, 8.72876187, 7.56794622]),\n",
       "  array([8.50271414, 2.50081071, 7.44483387, 6.67206426, 4.95196328,\n",
       "         9.02398316, 8.78252976, 7.55368131]),\n",
       "  array([75348.31019911])),\n",
       " (array([8.76928857, 2.62834603, 6.056928  , 3.85091014, 8.63540793,\n",
       "         6.21728513, 8.91450645, 9.11925987]),\n",
       "  array([8.75878349, 2.50030961, 6.08619488, 3.85075649, 8.63215529,\n",
       "         6.20038259, 8.91775257, 9.11919723]),\n",
       "  array([75283.79397261])),\n",
       " (array([8.76928857, 2.62834603, 6.056928  , 3.85091014, 8.63540793,\n",
       "         6.21728513, 8.91450645, 9.11925987]),\n",
       "  array([8.75878349, 2.50030961, 6.08619488, 3.85075649, 8.63215529,\n",
       "         6.20038259, 8.91775257, 9.11919723]),\n",
       "  array([75283.79397261])),\n",
       " (array([6.80300303, 4.44188674, 5.09232451, 4.49702205, 8.23280156,\n",
       "         6.85857552, 8.44098143, 8.16072244]),\n",
       "  array([6.65600029, 2.50037895, 5.60269841, 4.48811618, 8.18085607,\n",
       "         6.62444563, 8.48420922, 8.15272053]),\n",
       "  array([75256.21291677])),\n",
       " (array([6.80300303, 4.44188674, 5.09232451, 4.49702205, 8.23280156,\n",
       "         6.85857552, 8.44098143, 8.16072244]),\n",
       "  array([6.65600029, 2.50037895, 5.60269841, 4.48811618, 8.18085607,\n",
       "         6.62444563, 8.48420922, 8.15272053]),\n",
       "  array([75256.21291677])),\n",
       " (array([3.21984115, 5.39741914, 3.06195252, 3.71725886, 3.17636821,\n",
       "         6.49714444, 4.97751651, 3.937595  ]),\n",
       "  array([3.03674118, 2.50114166, 4.06161644, 3.72499718, 3.08440253,\n",
       "         6.05916178, 5.09322235, 3.87730039]),\n",
       "  array([75018.97540322])),\n",
       " (array([3.21984115, 5.39741914, 3.06195252, 3.71725886, 3.17636821,\n",
       "         6.49714444, 4.97751651, 3.937595  ]),\n",
       "  array([3.03674118, 2.50114166, 4.06161644, 3.72499718, 3.08440253,\n",
       "         6.05916178, 5.09322235, 3.87730039]),\n",
       "  array([75018.97540322])),\n",
       " (array([5.79794783, 3.9627206 , 4.23564584, 6.31557635, 7.74409975,\n",
       "         5.68866027, 8.41799693, 3.25907859]),\n",
       "  array([5.69683718, 2.50022264, 4.64333888, 6.29845837, 7.67587804,\n",
       "         5.49558983, 8.44479351, 3.26415232]),\n",
       "  array([74915.93772219])),\n",
       " (array([4.73444547, 4.55713543, 4.76768044, 3.43126218, 6.18119505,\n",
       "         7.97143628, 6.97046524, 6.40215195]),\n",
       "  array([4.58418915, 2.50048681, 5.33481887, 3.43348264, 6.13000496,\n",
       "         7.72655738, 7.04947791, 6.38425255]),\n",
       "  array([74743.13982339])),\n",
       " (array([7.73957652, 5.27381196, 4.09706971, 7.71272833, 8.64466748,\n",
       "         5.33383564, 7.07827247, 8.3562118 ]),\n",
       "  array([7.53584592, 2.50023646, 4.92516517, 7.64836211, 8.55567279,\n",
       "         4.9353844 , 7.12989014, 8.33752625]),\n",
       "  array([74196.28999845])),\n",
       " (array([7.73957652, 5.27381196, 4.09706971, 7.71272833, 8.64466748,\n",
       "         5.33383564, 7.07827247, 8.3562118 ]),\n",
       "  array([7.53584592, 2.50023646, 4.92516517, 7.64836211, 8.55567279,\n",
       "         4.9353844 , 7.12989014, 8.33752625]),\n",
       "  array([74196.28999845])),\n",
       " (array([8.56216044, 4.33776831, 7.93039701, 4.37255955, 9.41797969,\n",
       "         8.24600758, 2.72828151, 6.3260847 ]),\n",
       "  array([8.3740127 , 2.50073193, 8.27868371, 4.34985358, 9.35672957,\n",
       "         7.93902184, 2.87419412, 6.34320808]),\n",
       "  array([73864.27040014])),\n",
       " (array([3.3540051 , 6.14184468, 4.14507689, 7.70715658, 5.39638998,\n",
       "         8.50625557, 5.5111194 , 9.66804906]),\n",
       "  array([3.11796602, 2.5010328 , 5.28486909, 7.59647652, 5.37510492,\n",
       "         8.08978272, 5.68624821, 9.56462436]),\n",
       "  array([73851.70633789])),\n",
       " (array([3.3540051 , 6.14184468, 4.14507689, 7.70715658, 5.39638998,\n",
       "         8.50625557, 5.5111194 , 9.66804906]),\n",
       "  array([3.11796602, 2.5010328 , 5.28486909, 7.59647652, 5.37510492,\n",
       "         8.08978272, 5.68624821, 9.56462436]),\n",
       "  array([73851.70633789])),\n",
       " (array([8.620305  , 6.52387304, 3.88667836, 4.19059542, 8.64203901,\n",
       "         6.0080067 , 6.58945111, 9.07213468]),\n",
       "  array([8.2988447 , 2.50065735, 5.25747142, 4.18335692, 8.53224468,\n",
       "         5.44966303, 6.65618638, 9.01797299]),\n",
       "  array([73797.40611016])),\n",
       " (array([8.620305  , 6.52387304, 3.88667836, 4.19059542, 8.64203901,\n",
       "         6.0080067 , 6.58945111, 9.07213468]),\n",
       "  array([8.2988447 , 2.50065735, 5.25747142, 4.18335692, 8.53224468,\n",
       "         5.44966303, 6.65618638, 9.01797299]),\n",
       "  array([73797.40611016])),\n",
       " (array([3.29835214, 3.93847072, 5.76595876, 8.42154026, 8.73202246,\n",
       "         8.79435178, 4.57508597, 9.83259606]),\n",
       "  array([3.19098009, 2.50051314, 6.10624844, 8.37599599, 8.71175908,\n",
       "         8.61673394, 4.66307057, 9.82781261]),\n",
       "  array([73784.60493494])),\n",
       " (array([5.51311011, 6.26822205, 3.42095021, 9.23743387, 7.05662242,\n",
       "         6.82980833, 8.57853598, 3.86830712]),\n",
       "  array([5.28248687, 2.50100299, 4.66199297, 9.10326674, 6.87299117,\n",
       "         6.42460718, 8.61616919, 3.83847343]),\n",
       "  array([73697.37713184])),\n",
       " (array([7.97029877, 4.9929493 , 4.98303034, 7.82559806, 4.23966158,\n",
       "         7.0562222 , 5.97291621, 8.46008862]),\n",
       "  array([7.77100218, 2.50062746, 5.65517551, 7.76426913, 4.19589749,\n",
       "         6.68247433, 6.0866194 , 8.39974049]),\n",
       "  array([73681.04873915])),\n",
       " (array([2.76717208, 2.22148718, 5.49317226, 6.27369954, 8.27637759,\n",
       "         9.23078108, 2.38469621, 9.09560579]),\n",
       "  array([2.76717208, 2.22148718, 5.49317226, 6.27369954, 8.27637759,\n",
       "         9.23078108, 2.38469621, 9.09560579]),\n",
       "  array([73628.16218462])),\n",
       " (array([2.59143951, 4.29600963, 9.92058926, 7.27019206, 7.07648428,\n",
       "         9.88620264, 5.32217423, 2.8871521 ]),\n",
       "  array([ 2.50006705,  3.24765356, 10.0750888 ,  7.23582834,  7.03389869,\n",
       "          9.73757635,  5.39226952,  2.89491508]),\n",
       "  array([73624.43270559])),\n",
       " (array([2.59143951, 4.29600963, 9.92058926, 7.27019206, 7.07648428,\n",
       "         9.88620264, 5.32217423, 2.8871521 ]),\n",
       "  array([ 2.50006705,  3.24765356, 10.0750888 ,  7.23582834,  7.03389869,\n",
       "          9.73757635,  5.39226952,  2.89491508]),\n",
       "  array([73624.43270559])),\n",
       " (array([9.52339449, 2.92213104, 6.26242017, 3.20492704, 4.98301278,\n",
       "         7.68433721, 7.19378052, 5.73431281]),\n",
       "  array([9.48584755, 2.50013311, 6.3565114 , 3.20611115, 4.97133696,\n",
       "         7.62514731, 7.21393822, 5.73130612]),\n",
       "  array([73446.6965008])),\n",
       " (array([9.52339449, 2.92213104, 6.26242017, 3.20492704, 4.98301278,\n",
       "         7.68433721, 7.19378052, 5.73431281]),\n",
       "  array([9.48584755, 2.50013311, 6.3565114 , 3.20611115, 4.97133696,\n",
       "         7.62514731, 7.21393822, 5.73130612]),\n",
       "  array([73446.6965008])),\n",
       " (array([9.52339449, 2.92213104, 6.26242017, 3.20492704, 4.98301278,\n",
       "         7.68433721, 7.19378052, 5.73431281]),\n",
       "  array([9.48584755, 2.50013311, 6.3565114 , 3.20611115, 4.97133696,\n",
       "         7.62514731, 7.21393822, 5.73130612]),\n",
       "  array([73446.6965008])),\n",
       " (array([3.51324278, 3.07721551, 6.85920372, 6.88783709, 9.21928215,\n",
       "         6.05656858, 5.77688879, 2.11950605]),\n",
       "  array([3.51324278, 3.07721551, 6.85920372, 6.88783709, 9.21928215,\n",
       "         6.05656858, 5.77688879, 2.11950605]),\n",
       "  array([73219.8737354])),\n",
       " (array([3.51324278, 3.07721551, 6.85920372, 6.88783709, 9.21928215,\n",
       "         6.05656858, 5.77688879, 2.11950605]),\n",
       "  array([3.51324278, 3.07721551, 6.85920372, 6.88783709, 9.21928215,\n",
       "         6.05656858, 5.77688879, 2.11950605]),\n",
       "  array([73219.8737354])),\n",
       " (array([6.18697757, 6.56882086, 5.81054738, 4.11732198, 8.37180208,\n",
       "         9.82121527, 4.39598059, 8.38180369]),\n",
       "  array([5.81653399, 2.50043775, 6.9145374 , 4.07390172, 8.31132818,\n",
       "         9.38436951, 4.6971382 , 8.34205251]),\n",
       "  array([73133.91439825])),\n",
       " (array([6.18697757, 6.56882086, 5.81054738, 4.11732198, 8.37180208,\n",
       "         9.82121527, 4.39598059, 8.38180369]),\n",
       "  array([5.81653399, 2.50043775, 6.9145374 , 4.07390172, 8.31132818,\n",
       "         9.38436951, 4.6971382 , 8.34205251]),\n",
       "  array([73133.91439825])),\n",
       " (array([9.22545751, 3.26607377, 8.6440655 , 9.16676316, 4.04581057,\n",
       "         9.74295102, 4.85377851, 8.01883358]),\n",
       "  array([9.15046639, 2.50064684, 8.76345582, 9.13993516, 4.03413992,\n",
       "         9.6273425 , 4.91529838, 8.00820475]),\n",
       "  array([72875.3046626])),\n",
       " (array([7.86588373, 4.44265088, 3.64158435, 8.98533422, 5.7447965 ,\n",
       "         5.47726131, 7.45525759, 3.07284886]),\n",
       "  array([7.72710964, 2.50079665, 4.21505873, 8.93560326, 5.65313379,\n",
       "         5.19323644, 7.50467214, 3.06096999]),\n",
       "  array([72497.07856293])),\n",
       " (array([7.86588373, 4.44265088, 3.64158435, 8.98533422, 5.7447965 ,\n",
       "         5.47726131, 7.45525759, 3.07284886]),\n",
       "  array([7.72710964, 2.50079665, 4.21505873, 8.93560326, 5.65313379,\n",
       "         5.19323644, 7.50467214, 3.06096999]),\n",
       "  array([72497.07856293])),\n",
       " (array([3.05074101, 3.76269683, 3.68850081, 7.14244229, 9.71011984,\n",
       "         7.10126391, 9.5367193 , 3.80073645]),\n",
       "  array([2.97428316, 2.50103601, 4.04534168, 7.12155259, 9.6553422 ,\n",
       "         6.98016349, 9.5564438 , 3.81266731]),\n",
       "  array([72202.79328168])),\n",
       " (array([3.05074101, 3.76269683, 3.68850081, 7.14244229, 9.71011984,\n",
       "         7.10126391, 9.5367193 , 3.80073645]),\n",
       "  array([2.97428316, 2.50103601, 4.04534168, 7.12155259, 9.6553422 ,\n",
       "         6.98016349, 9.5564438 , 3.81266731]),\n",
       "  array([72202.79328168])),\n",
       " (array([7.64918917, 2.89758583, 7.32706996, 4.79547298, 5.36945525,\n",
       "         9.89016881, 4.4248102 , 5.38032035]),\n",
       "  array([7.61194163, 2.50096885, 7.40297655, 4.79143355, 5.36009426,\n",
       "         9.83522697, 4.45660878, 5.37894365]),\n",
       "  array([72110.67916247])),\n",
       " (array([9.98909637, 3.78430854, 3.97169146, 6.37462202, 6.25493522,\n",
       "         4.41458679, 5.26680229, 8.00511753]),\n",
       "  array([9.88472421, 2.50110065, 4.34326224, 6.3601863 , 6.21836978,\n",
       "         4.19177182, 5.3136753 , 7.99007719]),\n",
       "  array([71851.21845597])),\n",
       " (array([7.06856866, 2.21573269, 6.34825617, 7.88644084, 7.55687063,\n",
       "         9.58805763, 3.48553571, 3.46890728]),\n",
       "  array([7.06856866, 2.21573269, 6.34825617, 7.88644084, 7.55687063,\n",
       "         9.58805763, 3.48553571, 3.46890728]),\n",
       "  array([71667.30592196])),\n",
       " (array([9.7911429 , 2.02615873, 4.52231431, 3.79395457, 6.29207474,\n",
       "         8.47450088, 6.39128321, 2.82500429]),\n",
       "  array([9.7911429 , 2.02615873, 4.52231431, 3.79395457, 6.29207474,\n",
       "         8.47450088, 6.39128321, 2.82500429]),\n",
       "  array([71448.21420179])),\n",
       " (array([9.7911429 , 2.02615873, 4.52231431, 3.79395457, 6.29207474,\n",
       "         8.47450088, 6.39128321, 2.82500429]),\n",
       "  array([9.7911429 , 2.02615873, 4.52231431, 3.79395457, 6.29207474,\n",
       "         8.47450088, 6.39128321, 2.82500429]),\n",
       "  array([71448.21420179])),\n",
       " (array([8.35167157, 2.53638853, 3.62191849, 5.94652202, 3.26035179,\n",
       "         5.44623108, 7.99273296, 3.63119396]),\n",
       "  array([8.34903837, 2.50056089, 3.63197699, 5.94633776, 3.25907482,\n",
       "         5.44100432, 7.99381283, 3.63077881]),\n",
       "  array([71354.70670069])),\n",
       " (array([8.35167157, 2.53638853, 3.62191849, 5.94652202, 3.26035179,\n",
       "         5.44623108, 7.99273296, 3.63119396]),\n",
       "  array([8.34903837, 2.50056089, 3.63197699, 5.94633776, 3.25907482,\n",
       "         5.44100432, 7.99381283, 3.63077881]),\n",
       "  array([71354.70670069])),\n",
       " (array([8.47545423, 6.57429383, 4.68323216, 6.30297731, 6.40871524,\n",
       "         9.50203937, 8.31188424, 7.28854553]),\n",
       "  array([8.13770542, 2.50023867, 5.88612586, 6.22287395, 6.32203789,\n",
       "         9.2118536 , 8.46045422, 7.19813243]),\n",
       "  array([71330.63586928])),\n",
       " (array([4.20966833, 4.82755058, 8.33112372, 6.05386772, 6.45425962,\n",
       "         7.42645223, 9.66165679, 9.32013025]),\n",
       "  array([4.12431272, 3.69966248, 8.55941837, 6.03079136, 6.43013798,\n",
       "         7.28204149, 9.67810038, 9.30534332]),\n",
       "  array([70463.27177306])),\n",
       " (array([4.20966833, 4.82755058, 8.33112372, 6.05386772, 6.45425962,\n",
       "         7.42645223, 9.66165679, 9.32013025]),\n",
       "  array([4.12457293, 3.70307509, 8.55875774, 6.03085477, 6.43021108,\n",
       "         7.28248928, 9.67803401, 9.30537712]),\n",
       "  array([70422.04950154])),\n",
       " (array([4.39264145, 2.27191115, 2.46288536, 3.14119009, 3.8611725 ,\n",
       "         6.42414569, 6.1764177 , 6.65003673]),\n",
       "  array([4.39264145, 2.27191115, 2.46288536, 3.14119009, 3.8611725 ,\n",
       "         6.42414569, 6.1764177 , 6.65003673]),\n",
       "  array([70165.37270756])),\n",
       " (array([5.109143  , 5.87968232, 2.62457319, 4.73146964, 4.27903775,\n",
       "         8.8700357 , 8.53360342, 4.26528994]),\n",
       "  array([4.90039648, 2.50066961, 3.81896926, 4.72933391, 4.18034433,\n",
       "         8.61724611, 8.62636452, 4.1905141 ]),\n",
       "  array([70083.90528667])),\n",
       " (array([5.109143  , 5.87968232, 2.62457319, 4.73146964, 4.27903775,\n",
       "         8.8700357 , 8.53360342, 4.26528994]),\n",
       "  array([4.90039648, 2.50066961, 3.81896926, 4.72933391, 4.18034433,\n",
       "         8.61724611, 8.62636452, 4.1905141 ]),\n",
       "  array([70083.90528667])),\n",
       " (array([5.109143  , 5.87968232, 2.62457319, 4.73146964, 4.27903775,\n",
       "         8.8700357 , 8.53360342, 4.26528994]),\n",
       "  array([4.90039648, 2.50066961, 3.81896926, 4.72933391, 4.18034433,\n",
       "         8.61724611, 8.62636452, 4.1905141 ]),\n",
       "  array([70083.90528667])),\n",
       " (array([2.15196124, 4.35963291, 9.26497618, 7.90888302, 2.78174951,\n",
       "         5.73667108, 4.98554116, 7.05954161]),\n",
       "  array([2.15196124, 4.35963291, 9.26497618, 7.90888302, 2.78174951,\n",
       "         5.73667108, 4.98554116, 7.05954161]),\n",
       "  array([68439.25495977])),\n",
       " (array([5.74516326, 2.52413459, 4.40026463, 4.53536448, 5.00620419,\n",
       "         8.11704295, 2.55580086, 5.6120337 ]),\n",
       "  array([5.74327023, 2.50078248, 4.40649582, 4.53525649, 5.00569682,\n",
       "         8.11354979, 2.55761813, 5.61186353]),\n",
       "  array([67501.48045042])),\n",
       " (array([5.74516326, 2.52413459, 4.40026463, 4.53536448, 5.00620419,\n",
       "         8.11704295, 2.55580086, 5.6120337 ]),\n",
       "  array([5.74327023, 2.50078248, 4.40649582, 4.53525649, 5.00569682,\n",
       "         8.11354979, 2.55761813, 5.61186353]),\n",
       "  array([67501.48045042])),\n",
       " (array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([65431.41057217])),\n",
       " (array([4.42431165, 2.29500017, 2.62214858, 6.27300698, 7.97761983,\n",
       "         8.26637821, 4.20514328, 5.36314825]),\n",
       "  array([4.42431165, 2.29500017, 2.62214858, 6.27300698, 7.97761983,\n",
       "         8.26637821, 4.20514328, 5.36314825]),\n",
       "  array([65425.48498542])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759])),\n",
       " (array([7.39791924, 4.56907301, 3.3302831 , 8.08162675, 7.59573274,\n",
       "         8.25658487, 4.14058781, 8.33017689]),\n",
       "  array([7.23607274, 2.50078492, 3.96217934, 8.02611347, 7.55967331,\n",
       "         8.00417478, 4.27957359, 8.30864864]),\n",
       "  array([65147.70686861])),\n",
       " (array([5.77545084, 2.56032368, 2.84687668, 5.7254832 , 8.17997311,\n",
       "         7.81889402, 6.69193553, 5.6801515 ]),\n",
       "  array([5.77129165, 2.50092301, 2.8642997 , 5.72506868, 8.17825028,\n",
       "         7.81258796, 6.6945951 , 5.68025489]),\n",
       "  array([64935.47018887])),\n",
       " (array([6.26869478, 2.7793247 , 2.85418812, 9.87090656, 8.23408446,\n",
       "         4.93358931, 2.15131749, 8.82074611]),\n",
       "  array([6.26869478, 2.7793247 , 2.85418812, 9.87090656, 8.23408446,\n",
       "         4.93358931, 2.15131749, 8.82074611]),\n",
       "  array([62247.78215649])),\n",
       " (array([9.49851485, 2.66765712, 2.51020965, 4.38218088, 4.97826409,\n",
       "         7.07132962, 5.61656206, 6.3882133 ]),\n",
       "  array([9.48527881, 2.50007603, 2.56188766, 4.38272793, 4.9745032 ,\n",
       "         7.04933486, 5.62547744, 6.38611538]),\n",
       "  array([62215.27498396])),\n",
       " (array([9.49851485, 2.66765712, 2.51020965, 4.38218088, 4.97826409,\n",
       "         7.07132962, 5.61656206, 6.3882133 ]),\n",
       "  array([9.48527881, 2.50007603, 2.56188766, 4.38272793, 4.9745032 ,\n",
       "         7.04933486, 5.62547744, 6.38611538]),\n",
       "  array([62215.27498396])),\n",
       " (array([6.27808473, 2.7833712 , 2.74428348, 8.30851092, 7.19099635,\n",
       "         8.49697235, 3.67889578, 3.3505978 ]),\n",
       "  array([6.25691176, 2.50040108, 2.82813357, 8.30211265, 7.18119196,\n",
       "         8.46259521, 3.69994873, 3.35130496]),\n",
       "  array([61582.50648557])),\n",
       " (array([2.12717718, 4.24935594, 4.83282894, 9.48940368, 6.69310519,\n",
       "         4.95351523, 4.76269905, 3.49531252]),\n",
       "  array([2.12717718, 4.24935594, 4.83282894, 9.48940368, 6.69310519,\n",
       "         4.95351523, 4.76269905, 3.49531252]),\n",
       "  array([58366.38822245])),\n",
       " (array([8.83000503, 3.1276826 , 3.02323138, 9.23555348, 2.24817777,\n",
       "         7.03314596, 8.09570781, 9.44711057]),\n",
       "  array([8.83000503, 3.1276826 , 3.02323138, 9.23555348, 2.24817777,\n",
       "         7.03314596, 8.09570781, 9.44711057]),\n",
       "  array([57975.68378887])),\n",
       " (array([3.45178366, 3.16493323, 3.21300463, 9.45070468, 8.7591459 ,\n",
       "         8.33173528, 2.20600069, 6.42737392]),\n",
       "  array([3.45178366, 3.16493323, 3.21300463, 9.45070468, 8.7591459 ,\n",
       "         8.33173528, 2.20600069, 6.42737392]),\n",
       "  array([56321.8718417])),\n",
       " (array([5.14102609, 5.07067598, 7.82167251, 5.88382289, 4.616266  ,\n",
       "         5.83559506, 2.12023149, 2.63866538]),\n",
       "  array([5.14102609, 5.07067598, 7.82167251, 5.88382289, 4.616266  ,\n",
       "         5.83559506, 2.12023149, 2.63866538]),\n",
       "  array([55912.15024953])),\n",
       " (array([2.26868462, 5.67271368, 9.03633636, 2.63628808, 9.05678772,\n",
       "         5.00173664, 2.85754855, 8.3474022 ]),\n",
       "  array([2.26868462, 5.67271368, 9.03633636, 2.63628808, 9.05678772,\n",
       "         5.00173664, 2.85754855, 8.3474022 ]),\n",
       "  array([55857.50408395])),\n",
       " (array([4.31666012, 3.86802621, 2.32225016, 2.61348146, 6.03567236,\n",
       "         4.31940999, 5.86434536, 9.52098839]),\n",
       "  array([4.31666012, 3.86802621, 2.32225016, 2.61348146, 6.03567236,\n",
       "         4.31940999, 5.86434536, 9.52098839]),\n",
       "  array([54154.08178909])),\n",
       " (array([5.26853998, 3.75434792, 3.49514773, 3.70263518, 7.36137403,\n",
       "         6.37198071, 2.18045654, 9.83002342]),\n",
       "  array([5.26853998, 3.75434792, 3.49514773, 3.70263518, 7.36137403,\n",
       "         6.37198071, 2.18045654, 9.83002342]),\n",
       "  array([54032.76959007])),\n",
       " (array([5.26853998, 3.75434792, 3.49514773, 3.70263518, 7.36137403,\n",
       "         6.37198071, 2.18045654, 9.83002342]),\n",
       "  array([5.26853998, 3.75434792, 3.49514773, 3.70263518, 7.36137403,\n",
       "         6.37198071, 2.18045654, 9.83002342]),\n",
       "  array([54032.76959007])),\n",
       " (array([8.45286853, 4.36425617, 6.61358073, 9.71639807, 9.59923875,\n",
       "         5.77161054, 2.09760667, 8.35827203]),\n",
       "  array([8.45286853, 4.36425617, 6.61358073, 9.71639807, 9.59923875,\n",
       "         5.77161054, 2.09760667, 8.35827203]),\n",
       "  array([53684.9258142])),\n",
       " (array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([51020.46621753])),\n",
       " (array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([51020.46621753])),\n",
       " (array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([51020.46621753])),\n",
       " (array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([51020.46621753])),\n",
       " (array([2.37535311, 6.02267168, 8.37377495, 4.53309991, 7.7243974 ,\n",
       "         6.89612848, 4.43453858, 3.57922737]),\n",
       "  array([2.37535311, 6.02267168, 8.37377495, 4.53309991, 7.7243974 ,\n",
       "         6.89612848, 4.43453858, 3.57922737]),\n",
       "  array([50140.49985484])),\n",
       " (array([2.37535311, 6.02267168, 8.37377495, 4.53309991, 7.7243974 ,\n",
       "         6.89612848, 4.43453858, 3.57922737]),\n",
       "  array([2.37535311, 6.02267168, 8.37377495, 4.53309991, 7.7243974 ,\n",
       "         6.89612848, 4.43453858, 3.57922737]),\n",
       "  array([50140.49985484])),\n",
       " (array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([48489.5205714])),\n",
       " (array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([48489.5205714])),\n",
       " (array([3.57861903, 6.280178  , 8.65911151, 9.68024777, 5.08156352,\n",
       "         7.32347276, 7.9498362 , 2.06146579]),\n",
       "  array([3.57861903, 6.280178  , 8.65911151, 9.68024777, 5.08156352,\n",
       "         7.32347276, 7.9498362 , 2.06146579]),\n",
       "  array([48111.02279279])),\n",
       " (array([9.01214383, 5.83317797, 7.79307746, 7.0585404 , 2.17666415,\n",
       "         9.6196165 , 4.56328074, 2.63224649]),\n",
       "  array([9.01214383, 5.83317797, 7.79307746, 7.0585404 , 2.17666415,\n",
       "         9.6196165 , 4.56328074, 2.63224649]),\n",
       "  array([45315.34319785])),\n",
       " (array([5.45449515, 6.41719777, 7.02404165, 3.21488489, 2.19329451,\n",
       "         8.42931613, 4.94438794, 3.32288331]),\n",
       "  array([5.45449515, 6.41719777, 7.02404165, 3.21488489, 2.19329451,\n",
       "         8.42931613, 4.94438794, 3.32288331]),\n",
       "  array([44620.6255282])),\n",
       " (array([2.42158645, 5.36692403, 4.19314939, 9.88923386, 3.3281671 ,\n",
       "         7.72567782, 2.5713273 , 4.58021405]),\n",
       "  array([2.42158645, 5.36692403, 4.19314939, 9.88923386, 3.3281671 ,\n",
       "         7.72567782, 2.5713273 , 4.58021405]),\n",
       "  array([43921.2861092])),\n",
       " (array([2.24938549, 7.1355691 , 9.60357587, 6.03064032, 9.55679646,\n",
       "         9.94656893, 5.29311738, 3.4859656 ]),\n",
       "  array([2.24938549, 7.1355691 , 9.60357587, 6.03064032, 9.55679646,\n",
       "         9.94656893, 5.29311738, 3.4859656 ]),\n",
       "  array([42781.92518807])),\n",
       " (array([5.56590714, 4.75504864, 2.00560628, 3.02576116, 6.22282128,\n",
       "         6.83490558, 9.92743919, 8.13267765]),\n",
       "  array([5.56590714, 4.75504864, 2.00560628, 3.02576116, 6.22282128,\n",
       "         6.83490558, 9.92743919, 8.13267765]),\n",
       "  array([42602.34718648])),\n",
       " (array([7.64521175, 5.78274711, 5.15054132, 2.47616186, 5.29481872,\n",
       "         8.75423079, 9.1371161 , 8.90628269]),\n",
       "  array([7.64521175, 5.78274711, 5.15054132, 2.47616186, 5.29481872,\n",
       "         8.75423079, 9.1371161 , 8.90628269]),\n",
       "  array([42158.80079566])),\n",
       " (array([7.64521175, 5.78274711, 5.15054132, 2.47616186, 5.29481872,\n",
       "         8.75423079, 9.1371161 , 8.90628269]),\n",
       "  array([7.64521175, 5.78274711, 5.15054132, 2.47616186, 5.29481872,\n",
       "         8.75423079, 9.1371161 , 8.90628269]),\n",
       "  array([42158.80079566])),\n",
       " (array([7.64521175, 5.78274711, 5.15054132, 2.47616186, 5.29481872,\n",
       "         8.75423079, 9.1371161 , 8.90628269]),\n",
       "  array([7.64521175, 5.78274711, 5.15054132, 2.47616186, 5.29481872,\n",
       "         8.75423079, 9.1371161 , 8.90628269]),\n",
       "  array([42158.80079566])),\n",
       " (array([7.04238323, 4.81812905, 2.19057057, 3.73409517, 8.33735545,\n",
       "         5.51629649, 2.58606507, 4.98470942]),\n",
       "  array([7.04238323, 4.81812905, 2.19057057, 3.73409517, 8.33735545,\n",
       "         5.51629649, 2.58606507, 4.98470942]),\n",
       "  array([42136.01669763])),\n",
       " (array([7.04238323, 4.81812905, 2.19057057, 3.73409517, 8.33735545,\n",
       "         5.51629649, 2.58606507, 4.98470942]),\n",
       "  array([7.04238323, 4.81812905, 2.19057057, 3.73409517, 8.33735545,\n",
       "         5.51629649, 2.58606507, 4.98470942]),\n",
       "  array([42136.01669763])),\n",
       " (array([3.35861851, 8.00191927, 9.67182006, 7.29808488, 9.83597288,\n",
       "         6.28172953, 2.87220783, 4.36908157]),\n",
       "  array([3.35620607, 7.98019768, 9.67813236, 7.29539599, 9.83322166,\n",
       "         6.27477075, 2.87290165, 4.36914761]),\n",
       "  array([41189.76255545])),\n",
       " (array([8.76154627, 5.68712093, 4.66332725, 9.91320942, 9.39240355,\n",
       "         6.94184719, 2.49427115, 5.93361662]),\n",
       "  array([8.76154627, 5.68712093, 4.66332725, 9.91320942, 9.39240355,\n",
       "         6.94184719, 2.49427115, 5.93361662]),\n",
       "  array([39612.20374999])),\n",
       " (array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([39531.53527268])),\n",
       " (array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([39531.53527268])),\n",
       " (array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([39531.53527268])),\n",
       " (array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([8.14316892, 7.45950784, 8.23798354, 9.26559455, 2.14234778,\n",
       "         9.39906092, 7.67183702, 4.93955909]),\n",
       "  array([39531.53527268])),\n",
       " (array([4.97407362, 8.85392438, 9.0420079 , 3.11567614, 3.9913667 ,\n",
       "         9.06772489, 5.74886625, 5.50569836]),\n",
       "  array([4.97405783, 8.85385785, 9.04206675, 3.11567116, 3.99135926,\n",
       "         9.06770881, 5.74886286, 5.50566913]),\n",
       "  array([39351.45507659])),\n",
       " (array([4.97407362, 8.85392438, 9.0420079 , 3.11567614, 3.9913667 ,\n",
       "         9.06772489, 5.74886625, 5.50569836]),\n",
       "  array([4.97405783, 8.85385785, 9.04206675, 3.11567116, 3.99135926,\n",
       "         9.06770881, 5.74886286, 5.50566913]),\n",
       "  array([39351.45507659])),\n",
       " (array([4.03335766, 7.63764846, 6.75125065, 4.09463841, 9.23440151,\n",
       "         6.63295844, 4.6558113 , 5.67161037]),\n",
       "  array([4.0320016 , 7.62062666, 6.76014853, 4.09412373, 9.23293555,\n",
       "         6.62984053, 4.65561004, 5.6712365 ]),\n",
       "  array([39277.94990784])),\n",
       " (array([4.03335766, 7.63764846, 6.75125065, 4.09463841, 9.23440151,\n",
       "         6.63295844, 4.6558113 , 5.67161037]),\n",
       "  array([4.0320016 , 7.62062666, 6.76014853, 4.09412373, 9.23293555,\n",
       "         6.62984053, 4.65561004, 5.6712365 ]),\n",
       "  array([39277.94990784])),\n",
       " (array([2.10299112, 9.24281642, 8.95995349, 3.61650842, 8.46059085,\n",
       "         9.63354476, 5.77238648, 9.81101014]),\n",
       "  array([2.10299112, 9.24281642, 8.95995349, 3.61650842, 8.46059085,\n",
       "         9.63354476, 5.77238648, 9.81101014]),\n",
       "  array([38252.51518433])),\n",
       " (array([8.93118239, 8.0127891 , 9.97709212, 8.00819807, 2.91740485,\n",
       "         9.66763027, 4.27111457, 6.41234245]),\n",
       "  array([8.93118239, 8.0127891 , 9.97709212, 8.00819807, 2.91740485,\n",
       "         9.66763027, 4.27111457, 6.41234245]),\n",
       "  array([38083.98579968])),\n",
       " (array([8.93118239, 8.0127891 , 9.97709212, 8.00819807, 2.91740485,\n",
       "         9.66763027, 4.27111457, 6.41234245]),\n",
       "  array([8.93118239, 8.0127891 , 9.97709212, 8.00819807, 2.91740485,\n",
       "         9.66763027, 4.27111457, 6.41234245]),\n",
       "  array([38083.98579968])),\n",
       " (array([4.91825354, 8.84363622, 8.66625149, 2.02358779, 9.74090145,\n",
       "         9.86560545, 7.37689289, 9.83481264]),\n",
       "  array([4.91825354, 8.84363622, 8.66625149, 2.02358779, 9.74090145,\n",
       "         9.86560545, 7.37689289, 9.83481264]),\n",
       "  array([37937.64892269])),\n",
       " (array([8.00038394, 8.01040703, 8.39539127, 3.58537272, 3.25838512,\n",
       "         8.3279503 , 8.18537281, 9.91936961]),\n",
       "  array([8.00020937, 8.00900868, 8.39595524, 3.5853498 , 3.25841723,\n",
       "         8.327774  , 8.18529484, 9.91912628]),\n",
       "  array([37860.44581604])),\n",
       " (array([7.95462855, 5.20594564, 2.04653061, 7.76957186, 8.74530383,\n",
       "         7.54793829, 5.16137886, 7.01085736]),\n",
       "  array([7.95462855, 5.20594564, 2.04653061, 7.76957186, 8.74530383,\n",
       "         7.54793829, 5.16137886, 7.01085736]),\n",
       "  array([37657.61163288])),\n",
       " (array([7.95462855, 5.20594564, 2.04653061, 7.76957186, 8.74530383,\n",
       "         7.54793829, 5.16137886, 7.01085736]),\n",
       "  array([7.95462855, 5.20594564, 2.04653061, 7.76957186, 8.74530383,\n",
       "         7.54793829, 5.16137886, 7.01085736]),\n",
       "  array([37657.61163288])),\n",
       " (array([9.46572723, 8.31048572, 9.53400387, 8.08596509, 8.53904379,\n",
       "         8.14953446, 2.57197839, 2.32150929]),\n",
       "  array([9.46572723, 8.31048572, 9.53400387, 8.08596509, 8.53904379,\n",
       "         8.14953446, 2.57197839, 2.32150929]),\n",
       "  array([37349.65648199])),\n",
       " (array([9.46572723, 8.31048572, 9.53400387, 8.08596509, 8.53904379,\n",
       "         8.14953446, 2.57197839, 2.32150929]),\n",
       "  array([9.46572723, 8.31048572, 9.53400387, 8.08596509, 8.53904379,\n",
       "         8.14953446, 2.57197839, 2.32150929]),\n",
       "  array([37349.65648199])),\n",
       " (array([9.37117828, 8.91561452, 9.63227616, 3.66125118, 9.98231288,\n",
       "         9.72152193, 9.9229497 , 7.03697657]),\n",
       "  array([9.37115685, 8.91559058, 9.63229089, 3.66124391, 9.98229796,\n",
       "         9.72156033, 9.92291858, 7.03696799]),\n",
       "  array([37082.08387827])),\n",
       " (array([9.37117828, 8.91561452, 9.63227616, 3.66125118, 9.98231288,\n",
       "         9.72152193, 9.9229497 , 7.03697657]),\n",
       "  array([9.37115685, 8.91559058, 9.63229089, 3.66124391, 9.98229796,\n",
       "         9.72156033, 9.92291858, 7.03696799]),\n",
       "  array([37082.08387827])),\n",
       " (array([7.82541368, 9.05357745, 6.12543613, 3.78607311, 3.17592024,\n",
       "         8.90417857, 5.31863657, 7.15969502]),\n",
       "  array([7.82540673, 9.05381069, 6.12572508, 3.78606955, 3.17593848,\n",
       "         8.90422755, 5.31861605, 7.15957332]),\n",
       "  array([36271.50883275])),\n",
       " (array([7.82541368, 9.05357745, 6.12543613, 3.78607311, 3.17592024,\n",
       "         8.90417857, 5.31863657, 7.15969502]),\n",
       "  array([7.82540673, 9.05381069, 6.12572508, 3.78606955, 3.17593848,\n",
       "         8.90422755, 5.31861605, 7.15957332]),\n",
       "  array([36271.50883275])),\n",
       " (array([6.08199065, 8.40358411, 5.89640539, 4.42759739, 7.53155837,\n",
       "         9.71729336, 3.73004212, 6.38113378]),\n",
       "  array([6.08199065, 8.40358411, 5.89640539, 4.42759739, 7.53155837,\n",
       "         9.71729336, 3.73004212, 6.38113378]),\n",
       "  array([36257.16387281])),\n",
       " (array([4.27814356, 8.96585095, 7.57448175, 8.7051576 , 4.56471608,\n",
       "         8.7318882 , 8.79337048, 7.01202137]),\n",
       "  array([4.27814356, 8.96585095, 7.57448175, 8.7051576 , 4.56471608,\n",
       "         8.7318882 , 8.79337048, 7.01202137]),\n",
       "  array([36172.93601571])),\n",
       " (array([4.27814356, 8.96585095, 7.57448175, 8.7051576 , 4.56471608,\n",
       "         8.7318882 , 8.79337048, 7.01202137]),\n",
       "  array([4.27814356, 8.96585095, 7.57448175, 8.7051576 , 4.56471608,\n",
       "         8.7318882 , 8.79337048, 7.01202137]),\n",
       "  array([36172.93601571])),\n",
       " (array([5.49215417, 8.26276766, 6.21403859, 8.44036831, 9.6772564 ,\n",
       "         6.78353181, 2.86848029, 5.2141351 ]),\n",
       "  array([5.49213116, 8.26255968, 6.21428262, 8.44030212, 9.67720861,\n",
       "         6.78346164, 2.86848771, 5.21412127]),\n",
       "  array([35955.68279589])),\n",
       " (array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([35670.99391096])),\n",
       " (array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([35670.99391096])),\n",
       " (array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([35670.99391096])),\n",
       " (array([2.41785327, 8.26680725, 4.55367652, 4.91451848, 5.77937036,\n",
       "         9.39042502, 2.42309088, 4.50039664]),\n",
       "  array([2.41785327, 8.26680725, 4.55367652, 4.91451848, 5.77937036,\n",
       "         9.39042502, 2.42309088, 4.50039664]),\n",
       "  array([34848.44729995])),\n",
       " (array([2.41785327, 8.26680725, 4.55367652, 4.91451848, 5.77937036,\n",
       "         9.39042502, 2.42309088, 4.50039664]),\n",
       "  array([2.41785327, 8.26680725, 4.55367652, 4.91451848, 5.77937036,\n",
       "         9.39042502, 2.42309088, 4.50039664]),\n",
       "  array([34848.44729995])),\n",
       " (array([3.55884111, 8.82054754, 5.0221135 , 9.09558674, 9.55597083,\n",
       "         9.22706312, 3.25523373, 5.21691621]),\n",
       "  array([3.55884111, 8.82054754, 5.0221135 , 9.09558674, 9.55597083,\n",
       "         9.22706312, 3.25523373, 5.21691621]),\n",
       "  array([34249.16780787])),\n",
       " (array([2.03244791, 8.18813841, 4.71158335, 7.96056465, 9.2849744 ,\n",
       "         7.50539063, 4.96642356, 4.54650204]),\n",
       "  array([2.03244791, 8.18813841, 4.71158335, 7.96056465, 9.2849744 ,\n",
       "         7.50539063, 4.96642356, 4.54650204]),\n",
       "  array([34107.72923143])),\n",
       " (array([9.09445845, 7.44103934, 4.08270257, 5.52141517, 8.45846964,\n",
       "         9.00860641, 6.31020385, 6.91349473]),\n",
       "  array([9.0944264 , 7.44074698, 4.08301334, 5.52139972, 8.45845309,\n",
       "         9.00865013, 6.31020487, 6.91346377]),\n",
       "  array([34058.74434734])),\n",
       " (array([9.09445845, 7.44103934, 4.08270257, 5.52141517, 8.45846964,\n",
       "         9.00860641, 6.31020385, 6.91349473]),\n",
       "  array([9.0944264 , 7.44074698, 4.08301334, 5.52139972, 8.45845309,\n",
       "         9.00865013, 6.31020487, 6.91346377]),\n",
       "  array([34058.74434734])),\n",
       " (array([2.22830359, 9.13134253, 2.92830428, 2.84712976, 4.10700216,\n",
       "         7.92714511, 6.64395367, 2.77072904]),\n",
       "  array([2.22830359, 9.13134253, 2.92830428, 2.84712976, 4.10700216,\n",
       "         7.92714511, 6.64395367, 2.77072904]),\n",
       "  array([32025.35632621])),\n",
       " (array([3.73422297, 7.87510607, 2.50984863, 7.37213942, 8.75389144,\n",
       "         7.97735359, 7.53928296, 8.55897645]),\n",
       "  array([3.73431445, 7.87339758, 2.51219814, 7.37194152, 8.75385511,\n",
       "         7.97776582, 7.53899611, 8.55874173]),\n",
       "  array([29694.96269604])),\n",
       " (array([3.73422297, 7.87510607, 2.50984863, 7.37213942, 8.75389144,\n",
       "         7.97735359, 7.53928296, 8.55897645]),\n",
       "  array([3.73431445, 7.87339758, 2.51219814, 7.37194152, 8.75385511,\n",
       "         7.97776582, 7.53899611, 8.55874173]),\n",
       "  array([29694.96269604]))]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key = lambda x: x[2], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c10686fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87504.62,\n",
       " 86722.18,\n",
       " 85846.05,\n",
       " 85234.52,\n",
       " 83528.12,\n",
       " 83442.09,\n",
       " 83051.34,\n",
       " 82927.4,\n",
       " 82061.53,\n",
       " 81642.69,\n",
       " 81555.23,\n",
       " 81538.36,\n",
       " 80338.0,\n",
       " 79837.12,\n",
       " 79274.52,\n",
       " 78784.51,\n",
       " 78464.02,\n",
       " 78285.78,\n",
       " 78227.84,\n",
       " 77779.3,\n",
       " 77117.16,\n",
       " 76251.66,\n",
       " 75869.35,\n",
       " 74482.89,\n",
       " 74264.98,\n",
       " 74121.92,\n",
       " 74057.05,\n",
       " 73939.99,\n",
       " 73631.16,\n",
       " 73446.17,\n",
       " 73263.34,\n",
       " 72485.31,\n",
       " 71832.66,\n",
       " 71412.88,\n",
       " 70886.62,\n",
       " 70830.75,\n",
       " 68788.69,\n",
       " 68580.09,\n",
       " 68412.84,\n",
       " 67842.77,\n",
       " 67582.01,\n",
       " 67541.22,\n",
       " 65967.9,\n",
       " 65755.58,\n",
       " 65196.87,\n",
       " 64191.2,\n",
       " 63832.05,\n",
       " 63545.63,\n",
       " 63428.37,\n",
       " 62995.52,\n",
       " 62259.07,\n",
       " 61916.03,\n",
       " 61777.55,\n",
       " 60676.16,\n",
       " 60241.04,\n",
       " 59576.45,\n",
       " 59528.58,\n",
       " 59376.38,\n",
       " 59242.72,\n",
       " 59079.92,\n",
       " 58941.78,\n",
       " 58933.1,\n",
       " 58280.82,\n",
       " 58009.89,\n",
       " 57964.61,\n",
       " 57829.19,\n",
       " 57613.95,\n",
       " 57492.59,\n",
       " 57476.48,\n",
       " 57130.39,\n",
       " 56982.9,\n",
       " 56945.66,\n",
       " 56933.59,\n",
       " 56623.36,\n",
       " 56583.86,\n",
       " 56483.61,\n",
       " 56466.14,\n",
       " 55940.92,\n",
       " 55933.92,\n",
       " 55512.09,\n",
       " 55372.77,\n",
       " 55176.56,\n",
       " 55084.65,\n",
       " 54923.63,\n",
       " 54917.07,\n",
       " 54591.75,\n",
       " 54481.37,\n",
       " 54169.0,\n",
       " 54082.5,\n",
       " 53435.33,\n",
       " 53361.03,\n",
       " 53131.57,\n",
       " 53128.57,\n",
       " 52277.82,\n",
       " 52040.86,\n",
       " 51484.24,\n",
       " 51478.34,\n",
       " 51216.0,\n",
       " 50891.45,\n",
       " 50145.55,\n",
       " 50091.75,\n",
       " 50014.9,\n",
       " 49986.26,\n",
       " 49868.83,\n",
       " 49796.77,\n",
       " 49490.61,\n",
       " 49161.92,\n",
       " 48776.66,\n",
       " 48273.97,\n",
       " 48261.59,\n",
       " 48190.71,\n",
       " 48098.7,\n",
       " 46953.95,\n",
       " 46524.35,\n",
       " 46129.22,\n",
       " 46091.66,\n",
       " 45922.62,\n",
       " 45878.44,\n",
       " 45864.03,\n",
       " 45782.82,\n",
       " 45501.43,\n",
       " 44826.27,\n",
       " 44633.94,\n",
       " 43917.88,\n",
       " 43852.49,\n",
       " 43735.25,\n",
       " 43498.45,\n",
       " 43223.52,\n",
       " 42834.68,\n",
       " 42826.96,\n",
       " 42712.16,\n",
       " 42488.39,\n",
       " 42392.09,\n",
       " 42310.96,\n",
       " 42216.71,\n",
       " 42126.63,\n",
       " 41955.81,\n",
       " 41604.7,\n",
       " 41575.52,\n",
       " 41272.68,\n",
       " 41209.06,\n",
       " 41014.12,\n",
       " 40838.39,\n",
       " 40674.69,\n",
       " 40365.63,\n",
       " 40312.21,\n",
       " 40240.8,\n",
       " 40218.37,\n",
       " 40209.09,\n",
       " 39934.32,\n",
       " 39898.93,\n",
       " 39893.78,\n",
       " 39812.22,\n",
       " 39772.36,\n",
       " 39632.97,\n",
       " 39455.15,\n",
       " 38696.92,\n",
       " 38631.77,\n",
       " 38479.91,\n",
       " 38288.45,\n",
       " 38272.51,\n",
       " 38228.54,\n",
       " 38203.33,\n",
       " 38061.4,\n",
       " 38055.51,\n",
       " 38007.75,\n",
       " 37963.37,\n",
       " 37868.46,\n",
       " 37774.8,\n",
       " 37664.28,\n",
       " 37555.24,\n",
       " 37259.05,\n",
       " 37199.73,\n",
       " 37090.28,\n",
       " 36968.19,\n",
       " 36848.17,\n",
       " 36297.46,\n",
       " 36190.71,\n",
       " 35755.04,\n",
       " 35681.61,\n",
       " 35386.52,\n",
       " 35125.81,\n",
       " 34622.34,\n",
       " 34621.07,\n",
       " 34553.53,\n",
       " 34098.0,\n",
       " 34050.94,\n",
       " 34024.41,\n",
       " 33497.77,\n",
       " 33448.64,\n",
       " 33214.96,\n",
       " 32969.1,\n",
       " 32915.28,\n",
       " 32312.23,\n",
       " 32187.64,\n",
       " 31592.12,\n",
       " 29418.82,\n",
       " 18493.71,\n",
       " 4246.804,\n",
       " 4182.584,\n",
       " 4169.862,\n",
       " 4146.092,\n",
       " 4085.169,\n",
       " 4028.038,\n",
       " 3919.829,\n",
       " 3914.767,\n",
       " 0.004902713,\n",
       " 0.004818215,\n",
       " 0.004691108,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['Altitude'], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b24df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
